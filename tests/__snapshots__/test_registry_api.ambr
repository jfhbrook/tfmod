# serializer version: 1
# name: test_get
  Module(id='hashicorp/consul/aws/0.11.0', owner='gruntwork-team', namespace='hashicorp', name='consul', version='0.11.0', provider='aws', provider_logo_url='/images/providers/aws.png', description='A Terraform Module for how to run Consul on AWS using Terraform and Packer', source='https://github.com/hashicorp/terraform-aws-consul', tag='v0.11.0', published_at=datetime.datetime(2021, 8, 16, 21, 32, 46, 147534, tzinfo=datetime.timezone.utc), downloads=185417, verified=False, root=ModuleInfo(path='', name='consul', readme="[![Maintained by Gruntwork.io](https://img.shields.io/badge/maintained%20by-gruntwork.io-%235849a6.svg)](https://gruntwork.io/?ref=repo_aws_consul)\n# Consul AWS Module\n\nThis repo contains a set of modules in the [modules folder](https://github.com/hashicorp/terraform-aws-consul/tree/master/modules) for deploying a [Consul](https://www.consul.io/) cluster on \n[AWS](https://aws.amazon.com/) using [Terraform](https://www.terraform.io/). Consul is a distributed, highly-available \ntool that you can use for service discovery and key/value storage. A Consul cluster typically includes a small number\nof server nodes, which are responsible for being part of the [consensus \nquorum](https://www.consul.io/docs/internals/consensus.html), and a larger number of client nodes, which you typically \nrun alongside your apps:\n\n![Consul architecture](https://github.com/hashicorp/terraform-aws-consul/blob/master/_docs/architecture.png?raw=true)\n\n\n\n## How to use this Module\n\nThis repo has the following folder structure:\n\n* [modules](https://github.com/hashicorp/terraform-aws-consul/tree/master/modules): This folder contains several standalone, reusable, production-grade modules that you can use to deploy Consul.\n* [examples](https://github.com/hashicorp/terraform-aws-consul/tree/master/examples): This folder shows examples of different ways to combine the modules in the `modules` folder to deploy Consul.\n* [test](https://github.com/hashicorp/terraform-aws-consul/tree/master/test): Automated tests for the modules and examples.\n* [root folder](https://github.com/hashicorp/terraform-aws-consul/tree/master): The root folder is *an example* of how to use the [consul-cluster module](https://github.com/hashicorp/terraform-aws-consul/tree/master/modules/consul-cluster) \n  module to deploy a [Consul](https://www.consul.io/) cluster in [AWS](https://aws.amazon.com/). The Terraform Registry requires the root of every repo to contain Terraform code, so we've put one of the examples there. This example is great for learning and experimenting, but for production use, please use the underlying modules in the [modules folder](https://github.com/hashicorp/terraform-aws-consul/tree/master/modules) directly.\n\nTo deploy Consul servers for production using this repo:\n\n1. Create a Consul AMI using a Packer template that references the [install-consul module](https://github.com/hashicorp/terraform-aws-consul/tree/master/modules/install-consul).\n   Here is an [example Packer template](https://github.com/hashicorp/terraform-aws-consul/tree/master/examples/consul-ami#quick-start). \n   \n   If you are just experimenting with this Module, you may find it more convenient to use one of our official public AMIs.\n   Check out the `aws_ami` data source usage in `main.tf` for how to auto-discover this AMI.\n  \n    **WARNING! Do NOT use these AMIs in your production setup. In production, you should build your own AMIs in your own \n    AWS account.**\n   \n1. Deploy that AMI across an Auto Scaling Group using the Terraform [consul-cluster module](https://github.com/hashicorp/terraform-aws-consul/tree/master/modules/consul-cluster) \n   and execute the [run-consul script](https://github.com/hashicorp/terraform-aws-consul/tree/master/modules/run-consul) with the `--server` flag during boot on each \n   Instance in the Auto Scaling Group to form the Consul cluster. Here is [an example Terraform \n   configuration](https://github.com/hashicorp/terraform-aws-consul/tree/master/examples/root-example#quick-start) to provision a Consul cluster.\n\nTo deploy Consul clients for production using this repo:\n \n1. Use the [install-consul module](https://github.com/hashicorp/terraform-aws-consul/tree/master/modules/install-consul) to install Consul alongside your application code.\n1. Before booting your app, execute the [run-consul script](https://github.com/hashicorp/terraform-aws-consul/tree/master/modules/run-consul) with `--client` flag.\n1. Your app can now use the local Consul agent for service discovery and key/value storage.\n1. Optionally, you can use the [install-dnsmasq module](https://github.com/hashicorp/terraform-aws-consul/tree/master/modules/install-dnsmasq) for Ubuntu 16.04 and Amazon Linux 2 or [setup-systemd-resolved](https://github.com/hashicorp/terraform-aws-consul/tree/master/modules/setup-systemd-resolved) for Ubuntu 18.04 and Ubuntu 20.04 to configure Consul as the DNS for a\n   specific domain (e.g. `.consul`) so that URLs such as `foo.service.consul` resolve automatically to the IP \n   address(es) for a service `foo` registered in Consul (all other domain names will be continue to resolve using the\n   default resolver on the OS).\n   \n \n\n\n## What's a Module?\n\nA Module is a canonical, reusable, best-practices definition for how to run a single piece of infrastructure, such \nas a database or server cluster. Each Module is created using [Terraform](https://www.terraform.io/), and\nincludes automated tests, examples, and documentation. It is maintained both by the open source community and \ncompanies that provide commercial support. \n\nInstead of figuring out the details of how to run a piece of infrastructure from scratch, you can reuse \nexisting code that has been proven in production. And instead of maintaining all that infrastructure code yourself, \nyou can leverage the work of the Module community to pick up infrastructure improvements through\na version number bump.\n \n \n \n## Who maintains this Module?\n\nThis Module is maintained by [Gruntwork](http://www.gruntwork.io/). If you're looking for help or commercial \nsupport, send an email to [modules@gruntwork.io](mailto:modules@gruntwork.io?Subject=Consul%20Module). \nGruntwork can help with:\n\n* Setup, customization, and support for this Module.\n* Modules for other types of infrastructure, such as VPCs, Docker clusters, databases, and continuous integration.\n* Modules that meet compliance requirements, such as HIPAA.\n* Consulting & Training on AWS, Terraform, and DevOps.\n\n\n\n## Code included in this Module:\n\n* [install-consul](https://github.com/hashicorp/terraform-aws-consul/tree/master/modules/install-consul): This module installs Consul using a\n  [Packer](https://www.packer.io/) template to create a Consul \n  [Amazon Machine Image (AMI)](http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/AMIs.html).\n\n* [consul-cluster](https://github.com/hashicorp/terraform-aws-consul/tree/master/modules/consul-cluster): The module includes Terraform code to deploy a Consul AMI across an [Auto \n  Scaling Group](https://aws.amazon.com/autoscaling/). \n  \n* [run-consul](https://github.com/hashicorp/terraform-aws-consul/tree/master/modules/run-consul): This module includes the scripts to configure and run Consul. It is used\n  by the above Packer module at build-time to set configurations, and by the Terraform module at runtime \n  with [User Data](http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/user-data.html#user-data-shell-scripts)\n  to create the cluster.\n\n* [install-dnsmasq module](https://github.com/hashicorp/terraform-aws-consul/tree/master/modules/install-dnsmasq): Install [Dnsmasq](http://www.thekelleys.org.uk/dnsmasq/doc.html)\n  for Ubuntu 16.04 and Amazon Linux 2 and configure it to forward requests for a specific domain to Consul. This allows you to use Consul as a DNS server\n  for URLs such as `foo.service.consul`.\n\n* [setup-systemd-resolved module](https://github.com/hashicorp/terraform-aws-consul/tree/master/modules/setup-systemd-resolved): Setup [systemd-resolved](https://www.freedesktop.org/software/systemd/man/resolved.conf.html)\n  for Ubuntu 18.04 and Ubuntu 20.04 and configure it to forward requests for a specific domain to Consul. This allows you to use Consul as a DNS server\n  for URLs such as `foo.service.consul`.\n\n* [consul-iam-policies](https://github.com/hashicorp/terraform-aws-consul/tree/master/modules/consul-iam-policies): Defines the IAM policies necessary for a Consul cluster. \n\n* [consul-security-group-rules](https://github.com/hashicorp/terraform-aws-consul/tree/master/modules/consul-security-group-rules): Defines the security group rules used by a \n  Consul cluster to control the traffic that is allowed to go in and out of the cluster.\n\n* [consul-client-security-group-rules](https://github.com/hashicorp/terraform-aws-consul/tree/master/modules/consul-client-security-group-rules): Defines the security group rules\n  used by a Consul agent to control the traffic that is allowed to go in and out.\n\n\n\n## How do I contribute to this Module?\n\nContributions are very welcome! Check out the [Contribution Guidelines](https://github.com/hashicorp/terraform-aws-consul/tree/master/CONTRIBUTING.md) for instructions.\n\n\n\n## How is this Module versioned?\n\nThis Module follows the principles of [Semantic Versioning](http://semver.org/). You can find each new release, \nalong with the changelog, in the [Releases Page](../../releases). \n\nDuring initial development, the major version will be 0 (e.g., `0.x.y`), which indicates the code does not yet have a \nstable API. Once we hit `1.0.0`, we will make every effort to maintain a backwards compatible API and use the MAJOR, \nMINOR, and PATCH versions on each release to indicate any incompatibilities. \n\n\n\n## License\n\nThis code is released under the Apache 2.0 License. Please see [LICENSE](https://github.com/hashicorp/terraform-aws-consul/tree/master/LICENSE) and [NOTICE](https://github.com/hashicorp/terraform-aws-consul/tree/master/NOTICE) for more \ndetails.\n\nCopyright &copy; 2017 Gruntwork, Inc.\n", empty=False, inputs=[Input(name='num_servers', type='number', description='The number of Consul server nodes to deploy. We strongly recommend using 3 or 5.', default='3', required=False), Input(name='num_clients', type='number', description='The number of Consul client nodes to deploy. You typically run the Consul client alongside your apps, so set this value to however many Instances make sense for your app code.', default='6', required=False), Input(name='cluster_tag_key', type='string', description='The tag the EC2 Instances will look for to automatically discover each other and form a cluster.', default='"consul-servers"', required=False), Input(name='ssh_key_name', type='string', description='The name of an EC2 Key Pair that can be used to SSH to the EC2 Instances in this cluster. Set to an empty string to not associate a Key Pair.', default='', required=True), Input(name='vpc_id', type='string', description='The ID of the VPC in which the nodes will be deployed.  Uses default VPC if not supplied.', default='', required=True), Input(name='enable_https_port', type='bool', description='If set to true, allow access to the Consul HTTPS port defined via the https_api_port variable.', default='false', required=False), Input(name='cluster_name', type='string', description='What to name the Consul cluster and all of its associated resources', default='"consul-example"', required=False), Input(name='spot_price', type='number', description='The maximum hourly price to pay for EC2 Spot Instances.', default='', required=True), Input(name='ami_id', type='string', description='The ID of the AMI to run in the cluster. This should be an AMI built from the Packer template under examples/consul-ami/consul.json. To keep this example simple, we run the same AMI on both server and client nodes, but in real-world usage, your client nodes would also run your apps. If the default value is used, Terraform will look up the latest AMI build automatically.', default='', required=True)], outputs=[Output(name='security_group_id_clients', description=''), Output(name='aws_region', description=''), Output(name='num_servers', description=''), Output(name='asg_name_servers', description=''), Output(name='launch_config_name_servers', description=''), Output(name='iam_role_id_servers', description=''), Output(name='num_clients', description=''), Output(name='asg_name_clients', description=''), Output(name='launch_config_name_clients', description=''), Output(name='iam_role_arn_servers', description=''), Output(name='security_group_id_servers', description=''), Output(name='iam_role_id_clients', description=''), Output(name='iam_role_arn_clients', description=''), Output(name='consul_servers_cluster_tag_key', description=''), Output(name='consul_servers_cluster_tag_value', description='')], dependencies=[], provider_dependencies=[Provider(name='aws', namespace='hashicorp', source='', version='')], resources=[]), submodules=[ModuleInfo(path='modules/consul-cluster', name='consul-cluster', readme='# Consul Cluster\n\nThis folder contains a [Terraform](https://www.terraform.io/) module to deploy a\n[Consul](https://www.consul.io/) cluster in [AWS](https://aws.amazon.com/) on top of an Auto Scaling Group. This module\nis designed to deploy an [Amazon Machine Image (AMI)](http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/AMIs.html)\nthat has Consul installed via the [install-consul](https://github.com/hashicorp/terraform-aws-consul/tree/master/modules/install-consul) module in this Module.\n\n\n\n## How do you use this module?\n\nThis folder defines a [Terraform module](https://www.terraform.io/docs/modules/usage.html), which you can use in your\ncode by adding a `module` configuration and setting its `source` parameter to URL of this folder:\n\n```hcl\nmodule "consul_cluster" {\n  # TODO: update this to the final URL\n  # Use version v0.0.5 of the consul-cluster module\n  source = "github.com/hashicorp/terraform-aws-consul//modules/consul-cluster?ref=v0.0.5"\n\n  # Specify the ID of the Consul AMI. You should build this using the scripts in the install-consul module.\n  ami_id = "ami-abcd1234"\n\n  # Add this tag to each node in the cluster\n  cluster_tag_key   = "consul-cluster"\n  cluster_tag_value = "consul-cluster-example"\n\n  # Configure and start Consul during boot. It will automatically form a cluster with all nodes that have that same tag.\n  user_data = <<-EOF\n              #!/bin/bash\n              /opt/consul/bin/run-consul --server --cluster-tag-key consul-cluster --cluster-tag-value consul-cluster-example\n              EOF\n\n  # ... See variables.tf for the other parameters you must define for the consul-cluster module\n}\n```\n\nNote the following parameters:\n\n* `source`: Use this parameter to specify the URL of the consul-cluster module. The double slash (`//`) is intentional\n  and required. Terraform uses it to specify subfolders within a Git repo (see [module\n  sources](https://www.terraform.io/docs/modules/sources.html)). The `ref` parameter specifies a specific Git tag in\n  this repo. That way, instead of using the latest version of this module from the `master` branch, which\n  will change every time you run Terraform, you\'re using a fixed version of the repo.\n\n* `ami_id`: Use this parameter to specify the ID of a Consul [Amazon Machine Image\n  (AMI)](http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/AMIs.html) to deploy on each server in the cluster. You\n  should install Consul in this AMI using the scripts in the [install-consul](https://github.com/hashicorp/terraform-aws-consul/tree/master/modules/install-consul) module.\n\n* `user_data`: Use this parameter to specify a [User\n  Data](http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/user-data.html#user-data-shell-scripts) script that each\n  server will run during boot. This is where you can use the [run-consul script](https://github.com/hashicorp/terraform-aws-consul/tree/master/modules/run-consul) to configure and\n  run Consul. The `run-consul` script is one of the scripts installed by the [install-consul](https://github.com/hashicorp/terraform-aws-consul/tree/master/modules/install-consul)\n  module.\n\nYou can find the other parameters in [variables.tf](variables.tf).\n\nCheck out the [consul-cluster example](https://github.com/hashicorp/terraform-aws-consul/tree/master/examples/root-example) for fully-working sample code.\n\n\n\n\n## How do you connect to the Consul cluster?\n\n### Using the HTTP API from your own computer\n\nIf you want to connect to the cluster from your own computer, the easiest way is to use the [HTTP\nAPI](https://www.consul.io/docs/agent/http.html). Note that this only works if the Consul cluster is running in public\nsubnets and/or your default VPC (as in the [consul-cluster example](https://github.com/hashicorp/terraform-aws-consul/tree/master/examples/root-example)), which is OK for testing\nand experimentation, but NOT recommended for production usage.\n\nTo use the HTTP API, you first need to get the public IP address of one of the Consul Servers. You can find Consul\nservers by using AWS tags. If you\'re running the [consul-cluster example](https://github.com/hashicorp/terraform-aws-consul/tree/master/examples/root-example), the\n[consul-examples-helper.sh script](https://github.com/hashicorp/terraform-aws-consul/tree/master/examples/consul-examples-helper/consul-examples-helper.sh) will do the tag lookup\nfor you automatically (note, you must have the [AWS CLI](https://aws.amazon.com/cli/),\n[jq](https://stedolan.github.io/jq/), and the [Consul agent](https://www.consul.io/) installed locally):\n\n```\n> ../consul-examples-helper/consul-examples-helper.sh\n\nYour Consul servers are running at the following IP addresses:\n\n34.200.218.123\n34.205.127.138\n34.201.165.11\n```\n\nYou can use one of these IP addresses with the `members` command to see a list of cluster nodes:\n\n```\n> consul members -http-addr=11.22.33.44:8500\n\nNode                 Address             Status  Type    Build  Protocol  DC\ni-0051c3ea00e9691a0  172.31.35.148:8301  alive   client  0.8.0  2         us-east-1\ni-00aea529cce1761d4  172.31.47.236:8301  alive   client  0.8.0  2         us-east-1\ni-01bc94ccfa032d82d  172.31.27.193:8301  alive   client  0.8.0  2         us-east-1\ni-04271e97808f15d63  172.31.25.174:8301  alive   server  0.8.0  2         us-east-1\ni-0483b07abe49ea7ff  172.31.5.42:8301    alive   client  0.8.0  2         us-east-1\ni-098fb1ebd5ca443bf  172.31.55.203:8301  alive   client  0.8.0  2         us-east-1\ni-0eb961b6825f7871c  172.31.65.9:8301    alive   client  0.8.0  2         us-east-1\ni-0ee6dcf715adbff5f  172.31.67.235:8301  alive   server  0.8.0  2         us-east-1\ni-0fd0e63682a94b245  172.31.54.84:8301   alive   server  0.8.0  2         us-east-1\n```\n\nYou can also try inserting a value:\n\n```\n> consul kv put -http-addr=11.22.33.44:8500 foo bar\n\nSuccess! Data written to: foo\n```\n\nAnd reading that value back:\n\n```\n> consul kv get -http-addr=11.22.33.44:8500 foo\n\nbar\n```\n\nFinally, you can try opening up the Consul UI in your browser at the URL `http://11.22.33.44:8500/ui/`.\n\n![Consul UI](https://github.com/hashicorp/terraform-aws-consul/blob/master/_docs/consul-ui-screenshot.png?raw=true)\n\n\n### Using the Consul agent on another EC2 Instance\n\nThe easiest way to run [Consul agent](https://www.consul.io/docs/agent/basics.html) and have it connect to the Consul\ncluster is to use the same EC2 tags the Consul servers use to discover each other during bootstrapping.\n\nFor example, imagine you deployed a Consul cluster in `us-east-1` as follows:\n\n<!-- TODO: update this to the final URL -->\n\n```hcl\nmodule "consul_cluster" {\n  source = "github.com/hashicorp/terraform-aws-consul//modules/consul-cluster?ref=v0.0.5"\n\n  # Add this tag to each node in the cluster\n  cluster_tag_key   = "consul-cluster"\n  cluster_tag_value = "consul-cluster-example"\n\n  # ... Other params omitted ...\n}\n```\n\nUsing the `retry-join-ec2-xxx` params, you can connect run a Consul agent on an EC2 Instance as follows:\n\n```\nconsul agent -retry-join-ec2-tag-key=consul-cluster -retry-join-ec2-tag-value=consul-cluster-example -data-dir=/tmp/consul\n```\n\nTwo important notes about this command:\n\n1. By default, the Consul cluster nodes advertise their *private* IP addresses, so the command above only works from\n   EC2 Instances inside the same VPC (or any VPC with proper peering connections and route table entries).\n1. In order to look up the EC2 tags, the EC2 Instance where you\'re running this command must have an IAM role with\n   the `ec2:DescribeInstances` permission.\n\n\n\n## How do you connect load balancers to the Auto Scaling Group (ASG)?\n\nYou can use the [`aws_autoscaling_attachment`](https://www.terraform.io/docs/providers/aws/r/autoscaling_attachment.html) resource.\n\nFor example, if you are using the new application or network load balancers:\n\n```hcl\nresource "aws_lb_target_group" "test" {\n  // ...\n}\n\n# Create a new Consul Cluster\nmodule "consul" {\n  source ="..."\n  // ...\n}\n\n# Create a new load balancer attachment\nresource "aws_autoscaling_attachment" "asg_attachment_bar" {\n  autoscaling_group_name = "${module.consul.asg_name}"\n  alb_target_group_arn   = "${aws_alb_target_group.test.arn}"\n}\n```\n\nIf you are using a "classic" load balancer:\n\n```hcl\n# Create a new load balancer\nresource "aws_elb" "bar" {\n  // ...\n}\n\n# Create a new Consul Cluster\nmodule "consul" {\n  source ="..."\n  // ...\n}\n\n# Create a new load balancer attachment\nresource "aws_autoscaling_attachment" "asg_attachment_bar" {\n  autoscaling_group_name = "${module.consul.asg_name}"\n  elb                    = "${aws_elb.bar.id}"\n}\n```\n\n\n\n## What\'s included in this module?\n\nThis module creates the following architecture:\n\n![Consul architecture](https://github.com/hashicorp/terraform-aws-consul/blob/master/_docs/architecture.png?raw=true)\n\nThis architecture consists of the following resources:\n\n* [Auto Scaling Group](#auto-scaling-group)\n* [EC2 Instance Tags](#ec2-instance-tags)\n* [Security Group](#security-group)\n* [IAM Role and Permissions](#iam-role-and-permissions)\n\n\n### Auto Scaling Group\n\nThis module runs Consul on top of an [Auto Scaling Group (ASG)](https://aws.amazon.com/autoscaling/). Typically, you\nshould run the ASG with 3 or 5 EC2 Instances spread across multiple [Availability\nZones](http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/using-regions-availability-zones.html). Each of the EC2\nInstances should be running an AMI that has Consul installed via the [install-consul](https://github.com/hashicorp/terraform-aws-consul/tree/master/modules/install-consul)\nmodule. You pass in the ID of the AMI to run using the `ami_id` input parameter.\n\n\n### EC2 Instance Tags\n\nThis module allows you to specify a tag to add to each EC2 instance in the ASG. We recommend using this tag with the\n[retry_join_ec2](https://www.consul.io/docs/agent/options.html?#retry_join_ec2) configuration to allow the EC2\nInstances to find each other and automatically form a cluster.\n\n\n### Security Group\n\nEach EC2 Instance in the ASG has a Security Group that allows:\n\n* All outbound requests\n* All the inbound ports specified in the [Consul documentation](https://www.consul.io/docs/agent/options.html?#ports-used)\n\nThe Security Group ID is exported as an output variable if you need to add additional rules.\n\nCheck out the [Security section](#security) for more details.\n\n\n### IAM Role and Permissions\n\nEach EC2 Instance in the ASG has an [IAM Role](http://docs.aws.amazon.com/IAM/latest/UserGuide/id_roles.html) attached.\nWe give this IAM role a small set of IAM permissions that each EC2 Instance can use to automatically discover the other\nInstances in its ASG and form a cluster with them. See the [run-consul required permissions\ndocs](https://github.com/hashicorp/terraform-aws-consul/tree/master/modules/run-consul#required-permissions) for details.\n\nThe IAM Role ARN is exported as an output variable if you need to add additional permissions.\n\nYou can disable the creation of the IAM role and policies if needed by setting `enable_iam_setup` variable to false.  This allows you to create the role seperately from this module and supply the external role arn via the `iam_instance_profile_name` variable.\n\n\n## How do you roll out updates?\n\nIf you want to deploy a new version of Consul across the cluster, the best way to do that is to:\n\n1. Build a new AMI.\n1. Set the `ami_id` parameter to the ID of the new AMI.\n1. Run `terraform apply`.\n\nThis updates the Launch Configuration of the ASG, so any new Instances in the ASG will have your new AMI, but it does\nNOT actually deploy those new instances. To make that happen, you should do the following:\n\n1. Issue an API call to one of the old Instances in the ASG to have it leave gracefully. E.g.:\n\n    ```\n    curl -X PUT <OLD_INSTANCE_IP>:8500/v1/agent/leave\n    ```\n\n1. Once the instance has left the cluster, terminate it:\n\n    ```\n    aws ec2 terminate-instances --instance-ids <OLD_INSTANCE_ID>\n    ```\n\n1. After a minute or two, the ASG should automatically launch a new Instance, with the new AMI, to replace the old one.\n\n1. Wait for the new Instance to boot and join the cluster.\n\n1. Repeat these steps for each of the other old Instances in the ASG.\n\nWe will add a script in the future to automate this process (PRs are welcome!).\n\n\n\n\n## What happens if a node crashes?\n\nThere are two ways a Consul node may go down:\n\n1. The Consul process may crash. In that case, `systemd` should restart it automatically.\n1. The EC2 Instance running Consul dies. In that case, the Auto Scaling Group should launch a replacement automatically.\n   Note that in this case, since the Consul agent did not exit gracefully, and the replacement will have a different ID,\n   you may have to manually clean out the old nodes using the [force-leave\n   command](https://www.consul.io/docs/commands/force-leave.html). We may add a script to do this\n   automatically in the future. For more info, see the [Consul Outage\n   documentation](https://www.consul.io/docs/guides/outage.html).\n\n\n\n\n## Security\n\nHere are some of the main security considerations to keep in mind when using this module:\n\n1. [Encryption in transit](#encryption-in-transit)\n1. [Encryption at rest](#encryption-at-rest)\n1. [Dedicated instances](#dedicated-instances)\n1. [Security groups](#security-groups)\n1. [SSH access](#ssh-access)\n\n\n### Encryption in transit\n\nConsul can encrypt all of its network traffic. For instructions on enabling network encryption, have a look at the\n[How do you handle encryption documentation](https://github.com/hashicorp/terraform-aws-consul/tree/master/modules/run-consul#how-do-you-handle-encryption).\n\n\n### Encryption at rest\n\nThe EC2 Instances in the cluster store all their data on the root EBS Volume. To enable encryption for the data at\nrest, you must enable encryption in your Consul AMI. If you\'re creating the AMI using Packer (e.g. as shown in\nthe [consul-ami example](https://github.com/hashicorp/terraform-aws-consul/tree/master/examples/consul-ami)), you need to set the [encrypt_boot\nparameter](https://www.packer.io/docs/builders/amazon-ebs.html#encrypt_boot) to `true`.\n\n\n### Dedicated instances\n\nIf you wish to use dedicated instances, you can set the `tenancy` parameter to `"dedicated"` in this module.\n\n\n### Security groups\n\nThis module attaches a security group to each EC2 Instance that allows inbound requests as follows:\n\n* **Consul**: For all the [ports used by Consul](https://www.consul.io/docs/agent/options.html#ports), you can\n  use the `allowed_inbound_cidr_blocks` parameter to control the list of\n  [CIDR blocks](https://en.wikipedia.org/wiki/Classless_Inter-Domain_Routing) that will be allowed access and the `allowed_inbound_security_group_ids` parameter to control the security groups that will be allowed access.\n\n* **SSH**: For the SSH port (default: 22), you can use the `allowed_ssh_cidr_blocks` parameter to control the list of\n  [CIDR blocks](https://en.wikipedia.org/wiki/Classless_Inter-Domain_Routing) that will be allowed access. You can use the `allowed_inbound_ssh_security_group_ids` parameter to control the list of source Security Groups that will be allowed access.\n\nNote that all the ports mentioned above are configurable via the `xxx_port` variables (e.g. `server_rpc_port`). See\n[variables.tf](variables.tf) for the full list.\n\n\n\n### SSH access\n\nYou can associate an [EC2 Key Pair](http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ec2-key-pairs.html) with each\nof the EC2 Instances in this cluster by specifying the Key Pair\'s name in the `ssh_key_name` variable. If you don\'t\nwant to associate a Key Pair with these servers, set `ssh_key_name` to an empty string.\n\n\n\n\n\n## What\'s NOT included in this module?\n\nThis module does NOT handle the following items, which you may want to provide on your own:\n\n* [Monitoring, alerting, log aggregation](#monitoring-alerting-log-aggregation)\n* [VPCs, subnets, route tables](#vpcs-subnets-route-tables)\n* [DNS entries](#dns-entries)\n\n\n### Monitoring, alerting, log aggregation\n\nThis module does not include anything for monitoring, alerting, or log aggregation. All ASGs and EC2 Instances come\nwith limited [CloudWatch](https://aws.amazon.com/cloudwatch/) metrics built-in, but beyond that, you will have to\nprovide your own solutions.\n\n\n### VPCs, subnets, route tables\n\nThis module assumes you\'ve already created your network topology (VPC, subnets, route tables, etc). You will need to\npass in the the relevant info about your network topology (e.g. `vpc_id`, `subnet_ids`) as input variables to this\nmodule.\n\n\n### DNS entries\n\nThis module does not create any DNS entries for Consul (e.g. in Route 53).\n\n\n', empty=False, inputs=[Input(name='root_volume_type', type='string', description='The type of volume. Must be one of: standard, gp2, or io1.', default='"standard"', required=False), Input(name='additional_security_group_ids', type='list(string)', description='A list of additional security group IDs to add to Consul EC2 Instances', default='[]', required=False), Input(name='user_data', type='string', description='A User Data script to execute while the server is booting. We recommend passing in a bash script that executes the run-consul script, which should have been installed in the Consul AMI by the install-consul module.', default='', required=True), Input(name='allowed_ssh_security_group_ids', type='list(string)', description='A list of security group IDs from which the EC2 Instances will allow SSH connections', default='[]', required=False), Input(name='allowed_ssh_security_group_count', type='number', description="The number of entries in var.allowed_ssh_security_group_ids. Ideally, this value could be computed dynamically, but we pass this variable to a Terraform resource's 'count' property and Terraform requires that 'count' be computed with literals or data sources only.", default='0', required=False), Input(name='ssh_port', type='number', description='The port used for SSH connections', default='22', required=False), Input(name='enabled_metrics', type='list(string)', description='List of autoscaling group metrics to enable.', default='[]', required=False), Input(name='iam_instance_profile_name', type='string', description='If enable_iam_setup is false then this will be the name of the IAM instance profile to attach', default='', required=True), Input(name='server_rpc_port', type='number', description='The port used by servers to handle incoming requests from other agents.', default='8300', required=False), Input(name='cli_rpc_port', type='number', description='The port used by all agents to handle RPC from the CLI.', default='8400', required=False), Input(name='ami_id', type='string', description='The ID of the AMI to run in this cluster. Should be an AMI that had Consul installed and configured by the install-consul module.', default='', required=True), Input(name='vpc_id', type='string', description='The ID of the VPC in which to deploy the Consul cluster', default='', required=True), Input(name='cluster_tag_value', type='string', description='Add a tag with key var.clsuter_tag_key and this value to each Instance in the ASG. This can be used to automatically find other Consul nodes and form a cluster.', default='"auto-join"', required=False), Input(name='availability_zones', type='list(string)', description='The availability zones into which the EC2 Instances should be deployed. We recommend one availability zone per node in the cluster_size variable. At least one of var.subnet_ids or var.availability_zones must be non-empty.', default='', required=True), Input(name='associate_public_ip_address', type='bool', description='If set to true, associate a public IP address with each EC2 Instance in the cluster.', default='false', required=False), Input(name='root_volume_encrypted', type='bool', description='Encrypt the root volume at rest', default='false', required=False), Input(name='serf_wan_port', type='number', description='The port used by servers to gossip over the WAN to other servers.', default='8302', required=False), Input(name='security_group_tags', type='map(string)', description='Tags to be applied to the LC security group', default='{}', required=False), Input(name='spot_price', type='number', description='The maximum hourly price to pay for EC2 Spot Instances.', default='', required=True), Input(name='tenancy', type='string', description='The tenancy of the instance. Must be one of: null, default or dedicated. For EC2 Spot Instances only null or dedicated can be used.', default='', required=True), Input(name='enable_https_port', type='bool', description='If set to true, allow access to the Consul HTTPS port defined via the https_api_port variable.', default='false', required=False), Input(name='protect_from_scale_in', type='bool', description='(Optional) Allows setting instance protection. The autoscaling group will not select instances with this setting for termination during scale in events.', default='false', required=False), Input(name='cluster_name', type='string', description='The name of the Consul cluster (e.g. consul-stage). This variable is used to namespace all resources created by this module.', default='', required=True), Input(name='wait_for_capacity_timeout', type='string', description="A maximum duration that Terraform should wait for ASG instances to be healthy before timing out. Setting this to '0' causes Terraform to skip all Capacity Waiting behavior.", default='"10m"', required=False), Input(name='service_linked_role_arn', type='string', description='The ARN of the service-linked role that the ASG will use to call other AWS services', default='', required=True), Input(name='instance_type', type='string', description='The type of EC2 Instances to run for each node in the cluster (e.g. t2.micro).', default='', required=True), Input(name='allowed_inbound_cidr_blocks', type='list(string)', description='A list of CIDR-formatted IP address ranges from which the EC2 Instances will allow connections to Consul', default='', required=True), Input(name='allowed_inbound_security_group_count', type='number', description="The number of entries in var.allowed_inbound_security_group_ids. Ideally, this value could be computed dynamically, but we pass this variable to a Terraform resource's 'count' property and Terraform requires that 'count' be computed with literals or data sources only.", default='0', required=False), Input(name='health_check_grace_period', type='number', description='Time, in seconds, after instance comes into service before checking health.', default='300', required=False), Input(name='https_api_port', type='number', description='The port used by clients to talk to the HTTPS API. Only used if enable_https_port is set to true.', default='8501', required=False), Input(name='enable_iam_setup', type='bool', description='If true, create the IAM Role, IAM Instance Profile, and IAM Policies. If false, these will not be created, and you can pass in your own IAM Instance Profile via var.iam_instance_profile_name.', default='true', required=False), Input(name='cluster_tag_key', type='string', description='Add a tag with this key and the value var.cluster_tag_value to each Instance in the ASG. This can be used to automatically find other Consul nodes and form a cluster.', default='"consul-servers"', required=False), Input(name='ssh_key_name', type='string', description='The name of an EC2 Key Pair that can be used to SSH to the EC2 Instances in this cluster. Set to an empty string to not associate a Key Pair.', default='', required=True), Input(name='health_check_type', type='string', description='Controls how health checking is done. Must be one of EC2 or ELB.', default='"EC2"', required=False), Input(name='instance_profile_path', type='string', description='Path in which to create the IAM instance profile.', default='"/"', required=False), Input(name='serf_lan_port', type='number', description='The port used to handle gossip in the LAN. Required by all agents.', default='8301', required=False), Input(name='http_api_port', type='number', description='The port used by clients to talk to the HTTP API', default='8500', required=False), Input(name='iam_permissions_boundary', type='string', description='If set, restricts the created IAM role to the given permissions boundary', default='', required=True), Input(name='cluster_size', type='number', description='The number of nodes to have in the Consul cluster. We strongly recommended that you use either 3 or 5.', default='3', required=False), Input(name='allowed_ssh_cidr_blocks', type='list(string)', description='A list of CIDR-formatted IP address ranges from which the EC2 Instances will allow SSH connections', default='[]', required=False), Input(name='allowed_inbound_security_group_ids', type='list(string)', description='A list of security group IDs that will be allowed to connect to Consul', default='[]', required=False), Input(name='dns_port', type='number', description='The port used to resolve DNS queries.', default='8600', required=False), Input(name='tags', type='list(object({ key : string, value : string, propagate_at_launch : bool }))', description="List of extra tag blocks added to the autoscaling group configuration. Each element in the list is a map containing keys 'key', 'value', and 'propagate_at_launch' mapped to the respective values.", default='[]', required=False), Input(name='subnet_ids', type='list(string)', description='The subnet IDs into which the EC2 Instances should be deployed. We recommend one subnet ID per node in the cluster_size variable. At least one of var.subnet_ids or var.availability_zones must be non-empty.', default='', required=True), Input(name='termination_policies', type='string', description='A list of policies to decide how the instances in the auto scale group should be terminated. The allowed values are OldestInstance, NewestInstance, OldestLaunchConfiguration, ClosestToNextInstanceHour, Default.', default='"Default"', required=False), Input(name='lifecycle_hooks', type='map(any)', description='The lifecycle hooks to create that are triggered by the launch event. This is a map where the keys are the name of the hook and the values are an object with the keys and values defined in the lifecycle_hook block of the aws_autoscaling_group resource.  Default is no launch hooks', default='{}', required=False), Input(name='root_volume_ebs_optimized', type='bool', description='If true, the launched EC2 instance will be EBS-optimized.', default='false', required=False), Input(name='root_volume_size', type='number', description='The size, in GB, of the root EBS volume.', default='50', required=False), Input(name='root_volume_delete_on_termination', type='bool', description='Whether the volume should be destroyed on instance termination.', default='true', required=False)], outputs=[Output(name='launch_config_name', description='This is the name of the launch_configuration used to bootstrap the cluster instances'), Output(name='iam_role_arn', description='This is the arn of instance role if enable_iam_setup variable is set to true'), Output(name='iam_role_id', description='This is the id of instance role if enable_iam_setup variable is set to true'), Output(name='security_group_id', description='This is the id of security group that governs ingress and egress for the cluster instances'), Output(name='cluster_tag_key', description='This is the tag key used to allow the consul servers to autojoin'), Output(name='cluster_tag_value', description='This is the tag value used to allow the consul servers to autojoin'), Output(name='asg_name', description='This is the name for the autoscaling group generated by the module'), Output(name='cluster_size', description='This is the desired size of the consul cluster in the autoscaling group')], dependencies=[], provider_dependencies=[Provider(name='aws', namespace='', source='', version='')], resources=[Resource(name='launch_configuration', type='aws_launch_configuration'), Resource(name='lc_security_group', type='aws_security_group'), Resource(name='allow_ssh_inbound', type='aws_security_group_rule'), Resource(name='allow_ssh_inbound_from_security_group_ids', type='aws_security_group_rule'), Resource(name='allow_all_outbound', type='aws_security_group_rule'), Resource(name='instance_profile', type='aws_iam_instance_profile'), Resource(name='instance_role', type='aws_iam_role'), Resource(name='autoscaling_group', type='aws_autoscaling_group')]), ModuleInfo(path='modules/consul-security-group-rules', name='consul-security-group-rules', readme='# Consul Security Group Rules Module\n\nThis folder contains a [Terraform](https://www.terraform.io/) module that defines the security group rules used by a \n[Consul](https://www.consul.io/) cluster to control the traffic that is allowed to go in and out of the cluster. \n\nNormally, you\'d get these rules by default if you\'re using the [consul-cluster module](https://github.com/hashicorp/terraform-aws-consul/tree/master/modules/consul-cluster), but if \nyou\'re running Consul on top of a different cluster, then you can use this module to add the necessary security group \nrules to that cluster. For example, imagine you were using the [nomad-cluster \nmodule](https://github.com/hashicorp/terraform-aws-nomad/tree/master/modules/nomad-cluster) to run a cluster of \nservers that have both Nomad and Consul on each node:\n\n```hcl\nmodule "nomad_servers" {\n  source = "git::git@github.com:hashicorp/terraform-aws-nomad.git//modules/nomad-cluster?ref=v0.0.1"\n  \n  # This AMI has both Nomad and Consul installed\n  ami_id = "ami-1234abcd"\n}\n```\n\nThe `nomad-cluster` module will provide the security group rules for Nomad, but not for Consul. To ensure those servers\nhave the necessary ports open for using Consul, you can use this module as follows:\n\n```hcl\nmodule "security_group_rules" {\n  source = "git::git@github.com:hashicorp/terraform-aws-consul.git//modules/consul-security-group-rules?ref=v0.0.2"\n\n  security_group_id = "${module.nomad_servers.security_group_id}"\n  \n  # ... (other params omitted) ...\n}\n```\n\nNote the following parameters:\n\n* `source`: Use this parameter to specify the URL of this module. The double slash (`//`) is intentional \n  and required. Terraform uses it to specify subfolders within a Git repo (see [module \n  sources](https://www.terraform.io/docs/modules/sources.html)). The `ref` parameter specifies a specific Git tag in \n  this repo. That way, instead of using the latest version of this module from the `master` branch, which \n  will change every time you run Terraform, you\'re using a fixed version of the repo.\n\n* `security_group_id`: Use this parameter to specify the ID of the security group to which the rules in this module\n  should be added.\n  \nYou can find the other parameters in [variables.tf](variables.tf).\n\nCheck out the [consul-cluster example](https://github.com/hashicorp/terraform-aws-consul/tree/master/examples/root-example) for working sample code.\n', empty=False, inputs=[Input(name='security_group_id', type='string', description='The ID of the security group to which we should add the Consul security group rules', default='', required=True), Input(name='allowed_inbound_cidr_blocks', type='list(string)', description='A list of CIDR-formatted IP address ranges from which the EC2 Instances will allow connections to Consul', default='[]', required=False), Input(name='allowed_inbound_security_group_ids', type='list(string)', description='A list of security group IDs that will be allowed to connect to Consul', default='[]', required=False), Input(name='allowed_inbound_security_group_count', type='number', description="The number of entries in var.allowed_inbound_security_group_ids. Ideally, this value could be computed dynamically, but we pass this variable to a Terraform resource's 'count' property and Terraform requires that 'count' be computed with literals or data sources only.", default='0', required=False), Input(name='https_api_port', type='number', description='The port used by clients to talk to the HTTPS API. Only used if enable_https_port is set to true.', default='8501', required=False), Input(name='dns_port', type='number', description='The port used to resolve DNS queries.', default='8600', required=False), Input(name='server_rpc_port', type='number', description='The port used by servers to handle incoming requests from other agents.', default='8300', required=False), Input(name='cli_rpc_port', type='number', description='The port used by all agents to handle RPC from the CLI.', default='8400', required=False), Input(name='serf_lan_port', type='number', description='The port used to handle gossip in the LAN. Required by all agents.', default='8301', required=False), Input(name='serf_wan_port', type='number', description='The port used by servers to gossip over the WAN to other servers.', default='8302', required=False), Input(name='http_api_port', type='number', description='The port used by clients to talk to the HTTP API', default='8500', required=False), Input(name='enable_https_port', type='bool', description='If set to true, allow access to the Consul HTTPS port defined via the https_api_port variable.', default='false', required=False)], outputs=[], dependencies=[], provider_dependencies=[Provider(name='aws', namespace='', source='', version='')], resources=[Resource(name='allow_https_api_inbound_from_self', type='aws_security_group_rule'), Resource(name='allow_dns_udp_inbound_from_self', type='aws_security_group_rule'), Resource(name='allow_http_api_inbound', type='aws_security_group_rule'), Resource(name='allow_server_rpc_inbound_from_security_group_ids', type='aws_security_group_rule'), Resource(name='allow_serf_wan_udp_inbound_from_security_group_ids', type='aws_security_group_rule'), Resource(name='allow_http_api_inbound_from_self', type='aws_security_group_rule'), Resource(name='allow_serf_wan_tcp_inbound_from_security_group_ids', type='aws_security_group_rule'), Resource(name='allow_dns_udp_inbound_from_security_group_ids', type='aws_security_group_rule'), Resource(name='allow_server_rpc_inbound', type='aws_security_group_rule'), Resource(name='allow_cli_rpc_inbound', type='aws_security_group_rule'), Resource(name='allow_serf_wan_tcp_inbound', type='aws_security_group_rule'), Resource(name='allow_serf_wan_udp_inbound', type='aws_security_group_rule'), Resource(name='allow_server_rpc_inbound_from_self', type='aws_security_group_rule'), Resource(name='allow_serf_wan_udp_inbound_from_self', type='aws_security_group_rule'), Resource(name='allow_dns_tcp_inbound_from_self', type='aws_security_group_rule'), Resource(name='allow_dns_tcp_inbound', type='aws_security_group_rule'), Resource(name='allow_http_api_inbound_from_security_group_ids', type='aws_security_group_rule'), Resource(name='allow_https_api_inbound_from_security_group_ids', type='aws_security_group_rule'), Resource(name='allow_dns_tcp_inbound_from_security_group_ids', type='aws_security_group_rule'), Resource(name='allow_serf_wan_tcp_inbound_from_self', type='aws_security_group_rule'), Resource(name='allow_https_api_inbound', type='aws_security_group_rule'), Resource(name='allow_dns_udp_inbound', type='aws_security_group_rule'), Resource(name='allow_cli_rpc_inbound_from_security_group_ids', type='aws_security_group_rule'), Resource(name='allow_cli_rpc_inbound_from_self', type='aws_security_group_rule')]), ModuleInfo(path='modules/consul-client-security-group-rules', name='consul-client-security-group-rules', readme='# Consul Client Security Group Rules Module\n\nThis folder contains a [Terraform](https://www.terraform.io/) module that defines the security group rules used by a \n[Consul](https://www.consul.io/) client to control the traffic that is allowed to go in and out. \n\nNormally, you\'d get these rules by default if you\'re using the [consul-cluster module](https://github.com/hashicorp/terraform-aws-consul/tree/master/modules/consul-cluster), but if \nyou\'re running Consul on top of a different cluster, then you can use this module to add the necessary security group \nrules to that cluster. For example, imagine you were using the [vault-cluster \nmodule](https://github.com/hashicorp/terraform-aws-vault/tree/master/modules/vault-cluster) to run a cluster of \nservers that have both Vault and Consul agent on each node:\n\n```hcl\nmodule "vault_servers" {\n  source = "git::git@github.com:hashicorp/terraform-aws-vault.git//modules/vault-cluster?ref=v0.0.1"\n  \n  # This AMI has both Vault and Consul installed\n  ami_id = "ami-1234abcd"\n}\n```\n\nThe `vault-cluster` module will provide the security group rules for Vault, but not for the Consul agent. To ensure those servers\nhave the necessary ports open for using Consul, you can use this module as follows:\n\n```hcl\nmodule "security_group_rules" {\n  source = "git::git@github.com:hashicorp/terraform-aws-consul.git//modules/consul-client-security-group-rules?ref=v0.0.2"\n\n  security_group_id = "${module.vault_servers.security_group_id}"\n  \n  # ... (other params omitted) ...\n}\n```\n\nNote the following parameters:\n\n* `source`: Use this parameter to specify the URL of this module. The double slash (`//`) is intentional \n  and required. Terraform uses it to specify subfolders within a Git repo (see [module \n  sources](https://www.terraform.io/docs/modules/sources.html)). The `ref` parameter specifies a specific Git tag in \n  this repo. That way, instead of using the latest version of this module from the `master` branch, which \n  will change every time you run Terraform, you\'re using a fixed version of the repo.\n\n* `security_group_id`: Use this parameter to specify the ID of the security group to which the rules in this module\n  should be added.\n  \nYou can find the other parameters in [variables.tf](variables.tf).\n\nCheck out the [consul-cluster module](https://github.com/hashicorp/terraform-aws-consul/tree/master/modules/consul-cluster) for working sample code.\n', empty=False, inputs=[Input(name='allowed_inbound_security_group_ids', type='list(string)', description='A list of security group IDs that will be allowed to connect to Consul', default='[]', required=False), Input(name='allowed_inbound_security_group_count', type='string', description="The number of entries in var.allowed_inbound_security_group_ids. Ideally, this value could be computed dynamically, but we pass this variable to a Terraform resource's 'count' property and Terraform requires that 'count' be computed with literals or data sources only.", default='0', required=False), Input(name='serf_lan_port', type='string', description='The port used to handle gossip in the LAN. Required by all agents.', default='8301', required=False), Input(name='security_group_id', type='string', description='The ID of the security group to which we should add the Consul security group rules', default='', required=True), Input(name='allowed_inbound_cidr_blocks', type='list(string)', description='A list of CIDR-formatted IP address ranges from which the EC2 Instances will allow connections to Consul', default='[]', required=False)], outputs=[], dependencies=[], provider_dependencies=[Provider(name='aws', namespace='', source='', version='')], resources=[Resource(name='allow_serf_lan_tcp_inbound', type='aws_security_group_rule'), Resource(name='allow_serf_lan_udp_inbound', type='aws_security_group_rule'), Resource(name='allow_serf_lan_tcp_inbound_from_security_group_ids', type='aws_security_group_rule'), Resource(name='allow_serf_lan_udp_inbound_from_security_group_ids', type='aws_security_group_rule'), Resource(name='allow_serf_lan_tcp_inbound_from_self', type='aws_security_group_rule'), Resource(name='allow_serf_lan_udp_inbound_from_self', type='aws_security_group_rule')]), ModuleInfo(path='modules/consul-iam-policies', name='consul-iam-policies', readme='# Consul IAM Policies\n\nThis folder contains a [Terraform](https://www.terraform.io/) module that defines the IAM Policies used by a \n[Consul](https://www.consul.io/) cluster. \n\nNormally, you\'d get these policies by default if you\'re using the [consul-cluster submodule](https://github.com/hashicorp/terraform-aws-consul/tree/master/modules/consul-cluster), \nbut if you\'re running Consul on top of a different cluster (e.g. you\'re co-locating Consul with Nomad), then you can \nuse this module to add the necessary IAM policies to that that cluster. For example, imagine you were using the \n[nomad-cluster module](https://github.com/hashicorp/terraform-aws-nomad/tree/master/modules/nomad-cluster) to run a \ncluster of servers that have both Nomad and Consul on each node:\n\n```hcl\nmodule "nomad_servers" {\n  source = "git::git@github.com:hashicorp/terraform-aws-nomad.git//modules/nomad-cluster?ref=v0.0.1"\n  \n  # This AMI has both Nomad and Consul installed\n  ami_id = "ami-1234abcd"\n}\n```\n\nThe `nomad-cluster` module will provide the IAM policies for Nomad, but not for Consul. To ensure those servers\nhave the necessary IAM permissions to run Consul, you can use this module as follows:\n\n```hcl\nmodule "iam_policies" {\n  source = "git::git@github.com:hashicorp/terraform-aws-consul.git//modules/consul-iam-policies?ref=v0.0.2"\n\n  iam_role_id = "${module.nomad_servers.iam_role_id}"\n  \n  # ... (other params omitted) ...\n}\n```\n\nNote the following parameters:\n\n* `source`: Use this parameter to specify the URL of this module. The double slash (`//`) is intentional \n  and required. Terraform uses it to specify subfolders within a Git repo (see [module \n  sources](https://www.terraform.io/docs/modules/sources.html)). The `ref` parameter specifies a specific Git tag in \n  this repo. That way, instead of using the latest version of this module from the `master` branch, which \n  will change every time you run Terraform, you\'re using a fixed version of the repo.\n\n* `iam_role_id`: Use this parameter to specify the ID of the IAM Role to which the rules in this module\n  should be added.\n  \nYou can find the other parameters in [variables.tf](variables.tf).\n\nCheck out the [consul-cluster example](https://github.com/hashicorp/terraform-aws-consul/tree/master/examples/root-example) for working sample code.\n', empty=False, inputs=[Input(name='iam_role_id', type='string', description='The ID of the IAM Role to which these IAM policies should be attached', default='', required=True), Input(name='enabled', type='bool', description='Give the option to disable this module if required', default='true', required=False)], outputs=[], dependencies=[], provider_dependencies=[Provider(name='aws', namespace='', source='', version='')], resources=[Resource(name='auto_discover_cluster', type='aws_iam_role_policy')])], examples=[ModuleInfo(path='examples/example-with-encryption', name='example-with-encryption', readme="# Consul cluster with encryption example\n\nThis folder contains a set of Terraform manifest for deploying a Consul cluster in AWS, including a Packer manifest that creates an AMI with a set of insecured certs for TLS validation, as well as installing an updated version of the `run-consul` script that accepts parameters for enabling RPC and gossip encryption.\n\nThe resulting AMI id can then be passed as a parameter to `variables.tf`. The `enable_gossip_encryption` and `enable_rpc_encryption` variables are set to `true` by default in this example, but they don't have to be in your implementation. In this example they're passed as parameters to the `user_data` template to generate the flags passed to `run-consul` but you can use a different strategy.\n\nThe end result of this example should be a cluster of 3 Consul servers and 3 Consul clients, all running on individual EC2 instances. If the default variables are used, both gossip and RPC encryption will be enabled. You can validate this by trying to bring up another Consul node or cluster NOT running with encryption and attempt to join the existing cluster.\n\nRunning this example with encryption turned off and then attempt to upgrade it to use encryption is a good exercise to validate that a production cluster can be upgraded with minimal impact.\n\nTo understand more about how Consul handles encryption or how you can upgrade to use encryption without downtime, check out the [Consul encryption documentation](https://www.consul.io/docs/agent/encryption.html). **IMPORTANT:** The certs included in this repo are **NOT** meant to be used in production. You should generate your own certs if you're running this for anything other than experimenting or testing.\n\n## Quick start\n\nTo deploy a Consul cluster with encryption enabled:\n\n1. Create a new AMI using the Packer manifest and the certificates in the `packer` directory.\n1. Modify `main.tf` to add your provider credentials, VPC/subnet ids if you need to, etc.\n1. Modify `variables.tf` to customize the cluster. **NOTE:** the `gossip_encryption_key` variable must be a 16-byte key that can be generated offline with `consul keygen`. It's **NOT** a good idea to keep this key **in plain text** in source control. It should be encrypted beforehand (with something like KMS) and decrypted by Consul during boot.\n1. Run `terraform init`.\n1. Run `terraform apply`.\n1. `ssh` into one of the boxes and make sure all nodes correctly discover each other (by running `consul members` for example).\n1. You can also validate that encryption is turned on by looking at `/opt/consul/log/consul-stdout.log` and verifying you see `Encrypt: Gossip: true, TLS-Outgoing: true, TLS-Incoming: true`.", empty=False, inputs=[Input(name='vpc_id', type='string', description='The ID of the VPC in which the nodes will be deployed.  Uses default VPC if not supplied.', default='', required=True), Input(name='key_file_path', type='string', description='Path to the certificate key used to verify incoming connections.', default='"/opt/consul/tls/consul.key.pem"', required=False), Input(name='cluster_tag_key', type='string', description='The tag the EC2 Instances will look for to automatically discover each other and form a cluster.', default='"consul-servers"', required=False), Input(name='spot_price', type='string', description='The maximum hourly price to pay for EC2 Spot Instances.', default='', required=True), Input(name='gossip_encryption_key', type='string', description="16 byte cryptographic key to encrypt gossip traffic between nodes. Must set 'enable_gossip_encryption' to true for this to take effect. WARNING: Setting the encryption key here means it will be stored in plain text. We're doing this here to keep the example simple, but in production you should inject it more securely, e.g. retrieving it from KMS.", default='""', required=False), Input(name='ca_path', type='string', description='Path to the directory of CA files used to verify outgoing connections.', default='"/opt/consul/tls/ca"', required=False), Input(name='ssh_key_name', type='string', description='The name of an EC2 Key Pair that can be used to SSH to the EC2 Instances in this cluster. Set to an empty string to not associate a Key Pair.', default='', required=True), Input(name='enable_gossip_encryption', type='bool', description='Encrypt gossip traffic between nodes. Must also specify encryption key.', default='true', required=False), Input(name='enable_rpc_encryption', type='bool', description='Encrypt RPC traffic between nodes. Must also specify TLS certificates and keys.', default='true', required=False), Input(name='cert_file_path', type='string', description='Path to the certificate file used to verify incoming connections.', default='"/opt/consul/tls/consul.crt.pem"', required=False), Input(name='ami_id', type='string', description='The ID of the AMI to run in the cluster. This should be an AMI built from the Packer template under examples/example-with-encryption/packer/consul-with-certs.json. To keep this example simple, we run the same AMI on both server and client nodes, but in real-world usage, your client nodes would also run your apps. If the default value is used, Terraform will look up the latest AMI build automatically.', default='', required=True), Input(name='cluster_name', type='string', description='What to name the Consul cluster and all of its associated resources', default='"consul-example"', required=False), Input(name='num_servers', type='number', description='The number of Consul server nodes to deploy. We strongly recommend using 3 or 5.', default='3', required=False), Input(name='num_clients', type='number', description='The number of Consul client nodes to deploy. You typically run the Consul client alongside your apps, so set this value to however many Instances make sense for your app code.', default='3', required=False)], outputs=[Output(name='num_clients', description=''), Output(name='launch_config_name_clients', description=''), Output(name='asg_name_servers', description=''), Output(name='iam_role_arn_servers', description=''), Output(name='iam_role_arn_clients', description=''), Output(name='aws_region', description=''), Output(name='num_servers', description=''), Output(name='iam_role_id_servers', description=''), Output(name='asg_name_clients', description=''), Output(name='security_group_id_clients', description=''), Output(name='consul_servers_cluster_tag_value', description=''), Output(name='launch_config_name_servers', description=''), Output(name='security_group_id_servers', description=''), Output(name='iam_role_id_clients', description=''), Output(name='consul_servers_cluster_tag_key', description='')], dependencies=[], provider_dependencies=[Provider(name='aws', namespace='', source='', version='')], resources=[]), ModuleInfo(path='examples/example-with-custom-asg-role', name='example-with-custom-asg-role', readme="# Consul Cluster Example\n\nThis folder shows an example of Terraform code that uses the [consul-cluster module](https://github.com/hashicorp/terraform-aws-consul/tree/master/modules/consul-cluster) to deploy \na [Consul](https://www.consul.io/) cluster in [AWS](https://aws.amazon.com/). The cluster consists of two Auto Scaling\nGroups (ASGs): one with a small number of Consul server nodes, which are responsible for being part of the [consensus \nquorum](https://www.consul.io/docs/internals/consensus.html), and one with a larger number of client nodes, which \nwould typically run alongside your apps:\n\n![Consul architecture](https://github.com/hashicorp/terraform-aws-consul/blob/master/_docs/architecture.png?raw=true)\n\nThe Consul server nodes are launched using a custom autoscaling service-linked role for the autoscaling group instead of the default autoscaling service-linked role.  This enables a  custom role to be assigned which may be desired for using KMS encrypted AMIs.  [More Information](https://forums.aws.amazon.com/thread.jspa?threadID=277523)\n\nYou will need to create an [Amazon Machine Image (AMI)](http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/AMIs.html) \nthat has Consul installed, which you can do using the [consul-ami example](https://github.com/hashicorp/terraform-aws-consul/tree/master/examples/consul-ami)). Note that to keep \nthis example simple, both the server ASG and client ASG are running the exact same AMI. In real-world usage, you'd \nprobably have multiple client ASGs, and each of those ASGs would run a different AMI that has the Consul agent \ninstalled alongside your apps.\n\nFor more info on how the Consul cluster works, check out the [consul-cluster](https://github.com/hashicorp/terraform-aws-consul/tree/master/modules/consul-cluster) documentation.\n\n\n\n## Quick start\n\nTo deploy a Consul Cluster:\n\n1. `git clone` this repo to your computer.\n1. Optional: build a Consul AMI. See the [consul-ami example](https://github.com/hashicorp/terraform-aws-consul/tree/master/examples/consul-ami) documentation for instructions. Make sure to\n   note down the ID of the AMI.\n1. Install [Terraform](https://www.terraform.io/).\n1. Open `variables.tf`, set the environment variables specified at the top of the file, and fill in any other variables that\n   don't have a default. If you built a custom AMI, put the AMI ID into the `ami_id` variable. Otherwise, one of our\n   public example AMIs will be used by default. These AMIs are great for learning/experimenting, but are NOT\n   recommended for production use.\n1. Run `terraform init`.\n1. Run `terraform apply`.\n1. Run the [consul-examples-helper.sh script](https://github.com/hashicorp/terraform-aws-consul/tree/master/examples/consul-examples-helper/consul-examples-helper.sh) to \n   print out the IP addresses of the Consul servers and some example commands you can run to interact with the cluster:\n   `../consul-examples-helper/consul-examples-helper.sh`.\n\n", empty=False, inputs=[Input(name='vpc_id', type='string', description='The ID of the VPC in which the nodes will be deployed.  Uses default VPC if not supplied.', default='', required=True), Input(name='gossip_encryption_key', type='string', description="16 byte cryptographic key to encrypt gossip traffic between nodes. Must set 'enable_gossip_encryption' to true for this to take effect. WARNING: Setting the encryption key here means it will be stored in plain text. We're doing this here to keep the example simple, but in production you should inject it more securely, e.g. retrieving it from KMS.", default='', required=True), Input(name='consul_service_linked_role_suffix', type='string', description='Suffix for the aws_iam_service_linked_role created for the consul cluster auto scaling group to use', default='"test-consul-service-linked-role"', required=False), Input(name='ami_id', type='string', description='The ID of the AMI to run in the cluster. This should be an AMI built from the Packer template under examples/example-with-encryption/packer/consul-with-certs.json. To keep this example simple, we run the same AMI on both server and client nodes, but in real-world usage, your client nodes would also run your apps. If the default value is used, Terraform will look up the latest AMI build automatically.', default='', required=True), Input(name='ssh_key_name', type='string', description='The name of an EC2 Key Pair that can be used to SSH to the EC2 Instances in this cluster. Set to an empty string to not associate a Key Pair.', default='', required=True), Input(name='spot_price', type='string', description='The maximum hourly price to pay for EC2 Spot Instances.', default='', required=True), Input(name='cluster_name', type='string', description='What to name the Consul cluster and all of its associated resources', default='"consul-example"', required=False), Input(name='cluster_tag_key', type='string', description='The tag the EC2 Instances will look for to automatically discover each other and form a cluster.', default='"consul-servers"', required=False), Input(name='enable_gossip_encryption', type='bool', description='Encrypt gossip traffic between nodes. Must also specify encryption key.', default='true', required=False), Input(name='ca_path', type='string', description='Path to the directory of CA files used to verify outgoing connections.', default='"/opt/consul/tls/ca"', required=False), Input(name='cert_file_path', type='string', description='Path to the certificate file used to verify incoming connections.', default='"/opt/consul/tls/consul.crt.pem"', required=False), Input(name='num_clients', type='number', description='The number of Consul client nodes to deploy. You typically run the Consul client alongside your apps, so set this value to however many Instances make sense for your app code.', default='3', required=False), Input(name='enable_rpc_encryption', type='bool', description='Encrypt RPC traffic between nodes. Must also specify TLS certificates and keys.', default='true', required=False), Input(name='key_file_path', type='string', description='Path to the certificate key used to verify incoming connections.', default='"/opt/consul/tls/consul.key.pem"', required=False), Input(name='num_servers', type='number', description='The number of Consul server nodes to deploy. We strongly recommend using 3 or 5.', default='3', required=False)], outputs=[Output(name='launch_config_name_servers', description=''), Output(name='iam_role_arn_servers', description=''), Output(name='asg_name_clients', description=''), Output(name='launch_config_name_clients', description=''), Output(name='iam_role_id_clients', description=''), Output(name='consul_servers_cluster_tag_key', description=''), Output(name='iam_role_id_servers', description=''), Output(name='security_group_id_servers', description=''), Output(name='security_group_id_clients', description=''), Output(name='aws_region', description=''), Output(name='consul_servers_cluster_tag_value', description=''), Output(name='num_servers', description=''), Output(name='asg_name_servers', description=''), Output(name='num_clients', description=''), Output(name='iam_role_arn_clients', description='')], dependencies=[], provider_dependencies=[Provider(name='aws', namespace='', source='', version='')], resources=[Resource(name='consul_asg_role', type='aws_iam_service_linked_role')])], providers=['aws', 'azurerm', 'google'], versions=['0.0.1', '0.0.2', '0.0.3', '0.0.4', '0.0.5', '0.1.0', '0.1.1', '0.1.2', '0.2.0', '0.2.1', '0.2.2', '0.3.0', '0.3.1', '0.3.2', '0.3.3', '0.3.4', '0.3.5', '0.3.6', '0.3.7', '0.3.8', '0.3.9', '0.3.10', '0.4.0', '0.4.1', '0.4.2', '0.4.3', '0.4.4', '0.4.5', '0.5.0', '0.6.0', '0.6.1', '0.7.0', '0.7.1', '0.7.2', '0.7.3', '0.7.4', '0.7.5', '0.7.6', '0.7.7', '0.7.8', '0.7.9', '0.7.10', '0.7.11', '0.8.0', '0.8.1', '0.8.2', '0.8.3', '0.8.4', '0.8.5', '0.8.6', '0.9.0', '0.9.1', '0.9.2', '0.9.3', '0.10.0', '0.10.1', '0.11.0'], deprecation=None)
# ---
# name: test_latest
  ModuleList(meta=Meta(limit=15, current_offset=0, next_offset=None, prev_offset=None, next_url=None), modules=[ShortModule(id='hashicorp/consul/azurerm/0.0.5', owner='gruntwork-team', namespace='hashicorp', name='consul', version='0.0.5', provider='azurerm', provider_logo_url='/images/providers/azure.png?3', description='A Terraform Module for how to run Consul on AzureRM using Terraform and Packer', source='https://github.com/hashicorp/terraform-azurerm-consul', tag='v0.0.5', published_at=datetime.datetime(2019, 2, 14, 16, 55, 46, 934542, tzinfo=datetime.timezone.utc), downloads=5117, verified=False), ShortModule(id='hashicorp/consul/google/0.5.0', owner='gruntwork-team', namespace='hashicorp', name='consul', version='0.5.0', provider='google', provider_logo_url='/images/providers/google-cloud.svg', description='A Terraform Module for how to run Consul on Google Cloud using Terraform and Packer', source='https://github.com/hashicorp/terraform-google-consul', tag='v0.5.0', published_at=datetime.datetime(2020, 9, 18, 4, 12, 39, 976491, tzinfo=datetime.timezone.utc), downloads=9683, verified=False), ShortModule(id='hashicorp/consul/aws/0.11.0', owner='gruntwork-team', namespace='hashicorp', name='consul', version='0.11.0', provider='aws', provider_logo_url='/images/providers/aws.png', description='A Terraform Module for how to run Consul on AWS using Terraform and Packer', source='https://github.com/hashicorp/terraform-aws-consul', tag='v0.11.0', published_at=datetime.datetime(2021, 8, 16, 21, 32, 46, 147534, tzinfo=datetime.timezone.utc), downloads=185417, verified=False)])
# ---
# name: test_latest_for_provider
  Module(id='hashicorp/consul/aws/0.11.0', owner='gruntwork-team', namespace='hashicorp', name='consul', version='0.11.0', provider='aws', provider_logo_url='/images/providers/aws.png', description='A Terraform Module for how to run Consul on AWS using Terraform and Packer', source='https://github.com/hashicorp/terraform-aws-consul', tag='v0.11.0', published_at=datetime.datetime(2021, 8, 16, 21, 32, 46, 147534, tzinfo=datetime.timezone.utc), downloads=185417, verified=False, root=ModuleInfo(path='', name='consul', readme="[![Maintained by Gruntwork.io](https://img.shields.io/badge/maintained%20by-gruntwork.io-%235849a6.svg)](https://gruntwork.io/?ref=repo_aws_consul)\n# Consul AWS Module\n\nThis repo contains a set of modules in the [modules folder](https://github.com/hashicorp/terraform-aws-consul/tree/master/modules) for deploying a [Consul](https://www.consul.io/) cluster on \n[AWS](https://aws.amazon.com/) using [Terraform](https://www.terraform.io/). Consul is a distributed, highly-available \ntool that you can use for service discovery and key/value storage. A Consul cluster typically includes a small number\nof server nodes, which are responsible for being part of the [consensus \nquorum](https://www.consul.io/docs/internals/consensus.html), and a larger number of client nodes, which you typically \nrun alongside your apps:\n\n![Consul architecture](https://github.com/hashicorp/terraform-aws-consul/blob/master/_docs/architecture.png?raw=true)\n\n\n\n## How to use this Module\n\nThis repo has the following folder structure:\n\n* [modules](https://github.com/hashicorp/terraform-aws-consul/tree/master/modules): This folder contains several standalone, reusable, production-grade modules that you can use to deploy Consul.\n* [examples](https://github.com/hashicorp/terraform-aws-consul/tree/master/examples): This folder shows examples of different ways to combine the modules in the `modules` folder to deploy Consul.\n* [test](https://github.com/hashicorp/terraform-aws-consul/tree/master/test): Automated tests for the modules and examples.\n* [root folder](https://github.com/hashicorp/terraform-aws-consul/tree/master): The root folder is *an example* of how to use the [consul-cluster module](https://github.com/hashicorp/terraform-aws-consul/tree/master/modules/consul-cluster) \n  module to deploy a [Consul](https://www.consul.io/) cluster in [AWS](https://aws.amazon.com/). The Terraform Registry requires the root of every repo to contain Terraform code, so we've put one of the examples there. This example is great for learning and experimenting, but for production use, please use the underlying modules in the [modules folder](https://github.com/hashicorp/terraform-aws-consul/tree/master/modules) directly.\n\nTo deploy Consul servers for production using this repo:\n\n1. Create a Consul AMI using a Packer template that references the [install-consul module](https://github.com/hashicorp/terraform-aws-consul/tree/master/modules/install-consul).\n   Here is an [example Packer template](https://github.com/hashicorp/terraform-aws-consul/tree/master/examples/consul-ami#quick-start). \n   \n   If you are just experimenting with this Module, you may find it more convenient to use one of our official public AMIs.\n   Check out the `aws_ami` data source usage in `main.tf` for how to auto-discover this AMI.\n  \n    **WARNING! Do NOT use these AMIs in your production setup. In production, you should build your own AMIs in your own \n    AWS account.**\n   \n1. Deploy that AMI across an Auto Scaling Group using the Terraform [consul-cluster module](https://github.com/hashicorp/terraform-aws-consul/tree/master/modules/consul-cluster) \n   and execute the [run-consul script](https://github.com/hashicorp/terraform-aws-consul/tree/master/modules/run-consul) with the `--server` flag during boot on each \n   Instance in the Auto Scaling Group to form the Consul cluster. Here is [an example Terraform \n   configuration](https://github.com/hashicorp/terraform-aws-consul/tree/master/examples/root-example#quick-start) to provision a Consul cluster.\n\nTo deploy Consul clients for production using this repo:\n \n1. Use the [install-consul module](https://github.com/hashicorp/terraform-aws-consul/tree/master/modules/install-consul) to install Consul alongside your application code.\n1. Before booting your app, execute the [run-consul script](https://github.com/hashicorp/terraform-aws-consul/tree/master/modules/run-consul) with `--client` flag.\n1. Your app can now use the local Consul agent for service discovery and key/value storage.\n1. Optionally, you can use the [install-dnsmasq module](https://github.com/hashicorp/terraform-aws-consul/tree/master/modules/install-dnsmasq) for Ubuntu 16.04 and Amazon Linux 2 or [setup-systemd-resolved](https://github.com/hashicorp/terraform-aws-consul/tree/master/modules/setup-systemd-resolved) for Ubuntu 18.04 and Ubuntu 20.04 to configure Consul as the DNS for a\n   specific domain (e.g. `.consul`) so that URLs such as `foo.service.consul` resolve automatically to the IP \n   address(es) for a service `foo` registered in Consul (all other domain names will be continue to resolve using the\n   default resolver on the OS).\n   \n \n\n\n## What's a Module?\n\nA Module is a canonical, reusable, best-practices definition for how to run a single piece of infrastructure, such \nas a database or server cluster. Each Module is created using [Terraform](https://www.terraform.io/), and\nincludes automated tests, examples, and documentation. It is maintained both by the open source community and \ncompanies that provide commercial support. \n\nInstead of figuring out the details of how to run a piece of infrastructure from scratch, you can reuse \nexisting code that has been proven in production. And instead of maintaining all that infrastructure code yourself, \nyou can leverage the work of the Module community to pick up infrastructure improvements through\na version number bump.\n \n \n \n## Who maintains this Module?\n\nThis Module is maintained by [Gruntwork](http://www.gruntwork.io/). If you're looking for help or commercial \nsupport, send an email to [modules@gruntwork.io](mailto:modules@gruntwork.io?Subject=Consul%20Module). \nGruntwork can help with:\n\n* Setup, customization, and support for this Module.\n* Modules for other types of infrastructure, such as VPCs, Docker clusters, databases, and continuous integration.\n* Modules that meet compliance requirements, such as HIPAA.\n* Consulting & Training on AWS, Terraform, and DevOps.\n\n\n\n## Code included in this Module:\n\n* [install-consul](https://github.com/hashicorp/terraform-aws-consul/tree/master/modules/install-consul): This module installs Consul using a\n  [Packer](https://www.packer.io/) template to create a Consul \n  [Amazon Machine Image (AMI)](http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/AMIs.html).\n\n* [consul-cluster](https://github.com/hashicorp/terraform-aws-consul/tree/master/modules/consul-cluster): The module includes Terraform code to deploy a Consul AMI across an [Auto \n  Scaling Group](https://aws.amazon.com/autoscaling/). \n  \n* [run-consul](https://github.com/hashicorp/terraform-aws-consul/tree/master/modules/run-consul): This module includes the scripts to configure and run Consul. It is used\n  by the above Packer module at build-time to set configurations, and by the Terraform module at runtime \n  with [User Data](http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/user-data.html#user-data-shell-scripts)\n  to create the cluster.\n\n* [install-dnsmasq module](https://github.com/hashicorp/terraform-aws-consul/tree/master/modules/install-dnsmasq): Install [Dnsmasq](http://www.thekelleys.org.uk/dnsmasq/doc.html)\n  for Ubuntu 16.04 and Amazon Linux 2 and configure it to forward requests for a specific domain to Consul. This allows you to use Consul as a DNS server\n  for URLs such as `foo.service.consul`.\n\n* [setup-systemd-resolved module](https://github.com/hashicorp/terraform-aws-consul/tree/master/modules/setup-systemd-resolved): Setup [systemd-resolved](https://www.freedesktop.org/software/systemd/man/resolved.conf.html)\n  for Ubuntu 18.04 and Ubuntu 20.04 and configure it to forward requests for a specific domain to Consul. This allows you to use Consul as a DNS server\n  for URLs such as `foo.service.consul`.\n\n* [consul-iam-policies](https://github.com/hashicorp/terraform-aws-consul/tree/master/modules/consul-iam-policies): Defines the IAM policies necessary for a Consul cluster. \n\n* [consul-security-group-rules](https://github.com/hashicorp/terraform-aws-consul/tree/master/modules/consul-security-group-rules): Defines the security group rules used by a \n  Consul cluster to control the traffic that is allowed to go in and out of the cluster.\n\n* [consul-client-security-group-rules](https://github.com/hashicorp/terraform-aws-consul/tree/master/modules/consul-client-security-group-rules): Defines the security group rules\n  used by a Consul agent to control the traffic that is allowed to go in and out.\n\n\n\n## How do I contribute to this Module?\n\nContributions are very welcome! Check out the [Contribution Guidelines](https://github.com/hashicorp/terraform-aws-consul/tree/master/CONTRIBUTING.md) for instructions.\n\n\n\n## How is this Module versioned?\n\nThis Module follows the principles of [Semantic Versioning](http://semver.org/). You can find each new release, \nalong with the changelog, in the [Releases Page](../../releases). \n\nDuring initial development, the major version will be 0 (e.g., `0.x.y`), which indicates the code does not yet have a \nstable API. Once we hit `1.0.0`, we will make every effort to maintain a backwards compatible API and use the MAJOR, \nMINOR, and PATCH versions on each release to indicate any incompatibilities. \n\n\n\n## License\n\nThis code is released under the Apache 2.0 License. Please see [LICENSE](https://github.com/hashicorp/terraform-aws-consul/tree/master/LICENSE) and [NOTICE](https://github.com/hashicorp/terraform-aws-consul/tree/master/NOTICE) for more \ndetails.\n\nCopyright &copy; 2017 Gruntwork, Inc.\n", empty=False, inputs=[Input(name='num_servers', type='number', description='The number of Consul server nodes to deploy. We strongly recommend using 3 or 5.', default='3', required=False), Input(name='num_clients', type='number', description='The number of Consul client nodes to deploy. You typically run the Consul client alongside your apps, so set this value to however many Instances make sense for your app code.', default='6', required=False), Input(name='cluster_tag_key', type='string', description='The tag the EC2 Instances will look for to automatically discover each other and form a cluster.', default='"consul-servers"', required=False), Input(name='ssh_key_name', type='string', description='The name of an EC2 Key Pair that can be used to SSH to the EC2 Instances in this cluster. Set to an empty string to not associate a Key Pair.', default='', required=True), Input(name='vpc_id', type='string', description='The ID of the VPC in which the nodes will be deployed.  Uses default VPC if not supplied.', default='', required=True), Input(name='enable_https_port', type='bool', description='If set to true, allow access to the Consul HTTPS port defined via the https_api_port variable.', default='false', required=False), Input(name='cluster_name', type='string', description='What to name the Consul cluster and all of its associated resources', default='"consul-example"', required=False), Input(name='spot_price', type='number', description='The maximum hourly price to pay for EC2 Spot Instances.', default='', required=True), Input(name='ami_id', type='string', description='The ID of the AMI to run in the cluster. This should be an AMI built from the Packer template under examples/consul-ami/consul.json. To keep this example simple, we run the same AMI on both server and client nodes, but in real-world usage, your client nodes would also run your apps. If the default value is used, Terraform will look up the latest AMI build automatically.', default='', required=True)], outputs=[Output(name='security_group_id_clients', description=''), Output(name='aws_region', description=''), Output(name='num_servers', description=''), Output(name='asg_name_servers', description=''), Output(name='launch_config_name_servers', description=''), Output(name='iam_role_id_servers', description=''), Output(name='num_clients', description=''), Output(name='asg_name_clients', description=''), Output(name='launch_config_name_clients', description=''), Output(name='iam_role_arn_servers', description=''), Output(name='security_group_id_servers', description=''), Output(name='iam_role_id_clients', description=''), Output(name='iam_role_arn_clients', description=''), Output(name='consul_servers_cluster_tag_key', description=''), Output(name='consul_servers_cluster_tag_value', description='')], dependencies=[], provider_dependencies=[Provider(name='aws', namespace='hashicorp', source='', version='')], resources=[]), submodules=[ModuleInfo(path='modules/consul-cluster', name='consul-cluster', readme='# Consul Cluster\n\nThis folder contains a [Terraform](https://www.terraform.io/) module to deploy a\n[Consul](https://www.consul.io/) cluster in [AWS](https://aws.amazon.com/) on top of an Auto Scaling Group. This module\nis designed to deploy an [Amazon Machine Image (AMI)](http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/AMIs.html)\nthat has Consul installed via the [install-consul](https://github.com/hashicorp/terraform-aws-consul/tree/master/modules/install-consul) module in this Module.\n\n\n\n## How do you use this module?\n\nThis folder defines a [Terraform module](https://www.terraform.io/docs/modules/usage.html), which you can use in your\ncode by adding a `module` configuration and setting its `source` parameter to URL of this folder:\n\n```hcl\nmodule "consul_cluster" {\n  # TODO: update this to the final URL\n  # Use version v0.0.5 of the consul-cluster module\n  source = "github.com/hashicorp/terraform-aws-consul//modules/consul-cluster?ref=v0.0.5"\n\n  # Specify the ID of the Consul AMI. You should build this using the scripts in the install-consul module.\n  ami_id = "ami-abcd1234"\n\n  # Add this tag to each node in the cluster\n  cluster_tag_key   = "consul-cluster"\n  cluster_tag_value = "consul-cluster-example"\n\n  # Configure and start Consul during boot. It will automatically form a cluster with all nodes that have that same tag.\n  user_data = <<-EOF\n              #!/bin/bash\n              /opt/consul/bin/run-consul --server --cluster-tag-key consul-cluster --cluster-tag-value consul-cluster-example\n              EOF\n\n  # ... See variables.tf for the other parameters you must define for the consul-cluster module\n}\n```\n\nNote the following parameters:\n\n* `source`: Use this parameter to specify the URL of the consul-cluster module. The double slash (`//`) is intentional\n  and required. Terraform uses it to specify subfolders within a Git repo (see [module\n  sources](https://www.terraform.io/docs/modules/sources.html)). The `ref` parameter specifies a specific Git tag in\n  this repo. That way, instead of using the latest version of this module from the `master` branch, which\n  will change every time you run Terraform, you\'re using a fixed version of the repo.\n\n* `ami_id`: Use this parameter to specify the ID of a Consul [Amazon Machine Image\n  (AMI)](http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/AMIs.html) to deploy on each server in the cluster. You\n  should install Consul in this AMI using the scripts in the [install-consul](https://github.com/hashicorp/terraform-aws-consul/tree/master/modules/install-consul) module.\n\n* `user_data`: Use this parameter to specify a [User\n  Data](http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/user-data.html#user-data-shell-scripts) script that each\n  server will run during boot. This is where you can use the [run-consul script](https://github.com/hashicorp/terraform-aws-consul/tree/master/modules/run-consul) to configure and\n  run Consul. The `run-consul` script is one of the scripts installed by the [install-consul](https://github.com/hashicorp/terraform-aws-consul/tree/master/modules/install-consul)\n  module.\n\nYou can find the other parameters in [variables.tf](variables.tf).\n\nCheck out the [consul-cluster example](https://github.com/hashicorp/terraform-aws-consul/tree/master/examples/root-example) for fully-working sample code.\n\n\n\n\n## How do you connect to the Consul cluster?\n\n### Using the HTTP API from your own computer\n\nIf you want to connect to the cluster from your own computer, the easiest way is to use the [HTTP\nAPI](https://www.consul.io/docs/agent/http.html). Note that this only works if the Consul cluster is running in public\nsubnets and/or your default VPC (as in the [consul-cluster example](https://github.com/hashicorp/terraform-aws-consul/tree/master/examples/root-example)), which is OK for testing\nand experimentation, but NOT recommended for production usage.\n\nTo use the HTTP API, you first need to get the public IP address of one of the Consul Servers. You can find Consul\nservers by using AWS tags. If you\'re running the [consul-cluster example](https://github.com/hashicorp/terraform-aws-consul/tree/master/examples/root-example), the\n[consul-examples-helper.sh script](https://github.com/hashicorp/terraform-aws-consul/tree/master/examples/consul-examples-helper/consul-examples-helper.sh) will do the tag lookup\nfor you automatically (note, you must have the [AWS CLI](https://aws.amazon.com/cli/),\n[jq](https://stedolan.github.io/jq/), and the [Consul agent](https://www.consul.io/) installed locally):\n\n```\n> ../consul-examples-helper/consul-examples-helper.sh\n\nYour Consul servers are running at the following IP addresses:\n\n34.200.218.123\n34.205.127.138\n34.201.165.11\n```\n\nYou can use one of these IP addresses with the `members` command to see a list of cluster nodes:\n\n```\n> consul members -http-addr=11.22.33.44:8500\n\nNode                 Address             Status  Type    Build  Protocol  DC\ni-0051c3ea00e9691a0  172.31.35.148:8301  alive   client  0.8.0  2         us-east-1\ni-00aea529cce1761d4  172.31.47.236:8301  alive   client  0.8.0  2         us-east-1\ni-01bc94ccfa032d82d  172.31.27.193:8301  alive   client  0.8.0  2         us-east-1\ni-04271e97808f15d63  172.31.25.174:8301  alive   server  0.8.0  2         us-east-1\ni-0483b07abe49ea7ff  172.31.5.42:8301    alive   client  0.8.0  2         us-east-1\ni-098fb1ebd5ca443bf  172.31.55.203:8301  alive   client  0.8.0  2         us-east-1\ni-0eb961b6825f7871c  172.31.65.9:8301    alive   client  0.8.0  2         us-east-1\ni-0ee6dcf715adbff5f  172.31.67.235:8301  alive   server  0.8.0  2         us-east-1\ni-0fd0e63682a94b245  172.31.54.84:8301   alive   server  0.8.0  2         us-east-1\n```\n\nYou can also try inserting a value:\n\n```\n> consul kv put -http-addr=11.22.33.44:8500 foo bar\n\nSuccess! Data written to: foo\n```\n\nAnd reading that value back:\n\n```\n> consul kv get -http-addr=11.22.33.44:8500 foo\n\nbar\n```\n\nFinally, you can try opening up the Consul UI in your browser at the URL `http://11.22.33.44:8500/ui/`.\n\n![Consul UI](https://github.com/hashicorp/terraform-aws-consul/blob/master/_docs/consul-ui-screenshot.png?raw=true)\n\n\n### Using the Consul agent on another EC2 Instance\n\nThe easiest way to run [Consul agent](https://www.consul.io/docs/agent/basics.html) and have it connect to the Consul\ncluster is to use the same EC2 tags the Consul servers use to discover each other during bootstrapping.\n\nFor example, imagine you deployed a Consul cluster in `us-east-1` as follows:\n\n<!-- TODO: update this to the final URL -->\n\n```hcl\nmodule "consul_cluster" {\n  source = "github.com/hashicorp/terraform-aws-consul//modules/consul-cluster?ref=v0.0.5"\n\n  # Add this tag to each node in the cluster\n  cluster_tag_key   = "consul-cluster"\n  cluster_tag_value = "consul-cluster-example"\n\n  # ... Other params omitted ...\n}\n```\n\nUsing the `retry-join-ec2-xxx` params, you can connect run a Consul agent on an EC2 Instance as follows:\n\n```\nconsul agent -retry-join-ec2-tag-key=consul-cluster -retry-join-ec2-tag-value=consul-cluster-example -data-dir=/tmp/consul\n```\n\nTwo important notes about this command:\n\n1. By default, the Consul cluster nodes advertise their *private* IP addresses, so the command above only works from\n   EC2 Instances inside the same VPC (or any VPC with proper peering connections and route table entries).\n1. In order to look up the EC2 tags, the EC2 Instance where you\'re running this command must have an IAM role with\n   the `ec2:DescribeInstances` permission.\n\n\n\n## How do you connect load balancers to the Auto Scaling Group (ASG)?\n\nYou can use the [`aws_autoscaling_attachment`](https://www.terraform.io/docs/providers/aws/r/autoscaling_attachment.html) resource.\n\nFor example, if you are using the new application or network load balancers:\n\n```hcl\nresource "aws_lb_target_group" "test" {\n  // ...\n}\n\n# Create a new Consul Cluster\nmodule "consul" {\n  source ="..."\n  // ...\n}\n\n# Create a new load balancer attachment\nresource "aws_autoscaling_attachment" "asg_attachment_bar" {\n  autoscaling_group_name = "${module.consul.asg_name}"\n  alb_target_group_arn   = "${aws_alb_target_group.test.arn}"\n}\n```\n\nIf you are using a "classic" load balancer:\n\n```hcl\n# Create a new load balancer\nresource "aws_elb" "bar" {\n  // ...\n}\n\n# Create a new Consul Cluster\nmodule "consul" {\n  source ="..."\n  // ...\n}\n\n# Create a new load balancer attachment\nresource "aws_autoscaling_attachment" "asg_attachment_bar" {\n  autoscaling_group_name = "${module.consul.asg_name}"\n  elb                    = "${aws_elb.bar.id}"\n}\n```\n\n\n\n## What\'s included in this module?\n\nThis module creates the following architecture:\n\n![Consul architecture](https://github.com/hashicorp/terraform-aws-consul/blob/master/_docs/architecture.png?raw=true)\n\nThis architecture consists of the following resources:\n\n* [Auto Scaling Group](#auto-scaling-group)\n* [EC2 Instance Tags](#ec2-instance-tags)\n* [Security Group](#security-group)\n* [IAM Role and Permissions](#iam-role-and-permissions)\n\n\n### Auto Scaling Group\n\nThis module runs Consul on top of an [Auto Scaling Group (ASG)](https://aws.amazon.com/autoscaling/). Typically, you\nshould run the ASG with 3 or 5 EC2 Instances spread across multiple [Availability\nZones](http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/using-regions-availability-zones.html). Each of the EC2\nInstances should be running an AMI that has Consul installed via the [install-consul](https://github.com/hashicorp/terraform-aws-consul/tree/master/modules/install-consul)\nmodule. You pass in the ID of the AMI to run using the `ami_id` input parameter.\n\n\n### EC2 Instance Tags\n\nThis module allows you to specify a tag to add to each EC2 instance in the ASG. We recommend using this tag with the\n[retry_join_ec2](https://www.consul.io/docs/agent/options.html?#retry_join_ec2) configuration to allow the EC2\nInstances to find each other and automatically form a cluster.\n\n\n### Security Group\n\nEach EC2 Instance in the ASG has a Security Group that allows:\n\n* All outbound requests\n* All the inbound ports specified in the [Consul documentation](https://www.consul.io/docs/agent/options.html?#ports-used)\n\nThe Security Group ID is exported as an output variable if you need to add additional rules.\n\nCheck out the [Security section](#security) for more details.\n\n\n### IAM Role and Permissions\n\nEach EC2 Instance in the ASG has an [IAM Role](http://docs.aws.amazon.com/IAM/latest/UserGuide/id_roles.html) attached.\nWe give this IAM role a small set of IAM permissions that each EC2 Instance can use to automatically discover the other\nInstances in its ASG and form a cluster with them. See the [run-consul required permissions\ndocs](https://github.com/hashicorp/terraform-aws-consul/tree/master/modules/run-consul#required-permissions) for details.\n\nThe IAM Role ARN is exported as an output variable if you need to add additional permissions.\n\nYou can disable the creation of the IAM role and policies if needed by setting `enable_iam_setup` variable to false.  This allows you to create the role seperately from this module and supply the external role arn via the `iam_instance_profile_name` variable.\n\n\n## How do you roll out updates?\n\nIf you want to deploy a new version of Consul across the cluster, the best way to do that is to:\n\n1. Build a new AMI.\n1. Set the `ami_id` parameter to the ID of the new AMI.\n1. Run `terraform apply`.\n\nThis updates the Launch Configuration of the ASG, so any new Instances in the ASG will have your new AMI, but it does\nNOT actually deploy those new instances. To make that happen, you should do the following:\n\n1. Issue an API call to one of the old Instances in the ASG to have it leave gracefully. E.g.:\n\n    ```\n    curl -X PUT <OLD_INSTANCE_IP>:8500/v1/agent/leave\n    ```\n\n1. Once the instance has left the cluster, terminate it:\n\n    ```\n    aws ec2 terminate-instances --instance-ids <OLD_INSTANCE_ID>\n    ```\n\n1. After a minute or two, the ASG should automatically launch a new Instance, with the new AMI, to replace the old one.\n\n1. Wait for the new Instance to boot and join the cluster.\n\n1. Repeat these steps for each of the other old Instances in the ASG.\n\nWe will add a script in the future to automate this process (PRs are welcome!).\n\n\n\n\n## What happens if a node crashes?\n\nThere are two ways a Consul node may go down:\n\n1. The Consul process may crash. In that case, `systemd` should restart it automatically.\n1. The EC2 Instance running Consul dies. In that case, the Auto Scaling Group should launch a replacement automatically.\n   Note that in this case, since the Consul agent did not exit gracefully, and the replacement will have a different ID,\n   you may have to manually clean out the old nodes using the [force-leave\n   command](https://www.consul.io/docs/commands/force-leave.html). We may add a script to do this\n   automatically in the future. For more info, see the [Consul Outage\n   documentation](https://www.consul.io/docs/guides/outage.html).\n\n\n\n\n## Security\n\nHere are some of the main security considerations to keep in mind when using this module:\n\n1. [Encryption in transit](#encryption-in-transit)\n1. [Encryption at rest](#encryption-at-rest)\n1. [Dedicated instances](#dedicated-instances)\n1. [Security groups](#security-groups)\n1. [SSH access](#ssh-access)\n\n\n### Encryption in transit\n\nConsul can encrypt all of its network traffic. For instructions on enabling network encryption, have a look at the\n[How do you handle encryption documentation](https://github.com/hashicorp/terraform-aws-consul/tree/master/modules/run-consul#how-do-you-handle-encryption).\n\n\n### Encryption at rest\n\nThe EC2 Instances in the cluster store all their data on the root EBS Volume. To enable encryption for the data at\nrest, you must enable encryption in your Consul AMI. If you\'re creating the AMI using Packer (e.g. as shown in\nthe [consul-ami example](https://github.com/hashicorp/terraform-aws-consul/tree/master/examples/consul-ami)), you need to set the [encrypt_boot\nparameter](https://www.packer.io/docs/builders/amazon-ebs.html#encrypt_boot) to `true`.\n\n\n### Dedicated instances\n\nIf you wish to use dedicated instances, you can set the `tenancy` parameter to `"dedicated"` in this module.\n\n\n### Security groups\n\nThis module attaches a security group to each EC2 Instance that allows inbound requests as follows:\n\n* **Consul**: For all the [ports used by Consul](https://www.consul.io/docs/agent/options.html#ports), you can\n  use the `allowed_inbound_cidr_blocks` parameter to control the list of\n  [CIDR blocks](https://en.wikipedia.org/wiki/Classless_Inter-Domain_Routing) that will be allowed access and the `allowed_inbound_security_group_ids` parameter to control the security groups that will be allowed access.\n\n* **SSH**: For the SSH port (default: 22), you can use the `allowed_ssh_cidr_blocks` parameter to control the list of\n  [CIDR blocks](https://en.wikipedia.org/wiki/Classless_Inter-Domain_Routing) that will be allowed access. You can use the `allowed_inbound_ssh_security_group_ids` parameter to control the list of source Security Groups that will be allowed access.\n\nNote that all the ports mentioned above are configurable via the `xxx_port` variables (e.g. `server_rpc_port`). See\n[variables.tf](variables.tf) for the full list.\n\n\n\n### SSH access\n\nYou can associate an [EC2 Key Pair](http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ec2-key-pairs.html) with each\nof the EC2 Instances in this cluster by specifying the Key Pair\'s name in the `ssh_key_name` variable. If you don\'t\nwant to associate a Key Pair with these servers, set `ssh_key_name` to an empty string.\n\n\n\n\n\n## What\'s NOT included in this module?\n\nThis module does NOT handle the following items, which you may want to provide on your own:\n\n* [Monitoring, alerting, log aggregation](#monitoring-alerting-log-aggregation)\n* [VPCs, subnets, route tables](#vpcs-subnets-route-tables)\n* [DNS entries](#dns-entries)\n\n\n### Monitoring, alerting, log aggregation\n\nThis module does not include anything for monitoring, alerting, or log aggregation. All ASGs and EC2 Instances come\nwith limited [CloudWatch](https://aws.amazon.com/cloudwatch/) metrics built-in, but beyond that, you will have to\nprovide your own solutions.\n\n\n### VPCs, subnets, route tables\n\nThis module assumes you\'ve already created your network topology (VPC, subnets, route tables, etc). You will need to\npass in the the relevant info about your network topology (e.g. `vpc_id`, `subnet_ids`) as input variables to this\nmodule.\n\n\n### DNS entries\n\nThis module does not create any DNS entries for Consul (e.g. in Route 53).\n\n\n', empty=False, inputs=[Input(name='root_volume_type', type='string', description='The type of volume. Must be one of: standard, gp2, or io1.', default='"standard"', required=False), Input(name='additional_security_group_ids', type='list(string)', description='A list of additional security group IDs to add to Consul EC2 Instances', default='[]', required=False), Input(name='user_data', type='string', description='A User Data script to execute while the server is booting. We recommend passing in a bash script that executes the run-consul script, which should have been installed in the Consul AMI by the install-consul module.', default='', required=True), Input(name='allowed_ssh_security_group_ids', type='list(string)', description='A list of security group IDs from which the EC2 Instances will allow SSH connections', default='[]', required=False), Input(name='allowed_ssh_security_group_count', type='number', description="The number of entries in var.allowed_ssh_security_group_ids. Ideally, this value could be computed dynamically, but we pass this variable to a Terraform resource's 'count' property and Terraform requires that 'count' be computed with literals or data sources only.", default='0', required=False), Input(name='ssh_port', type='number', description='The port used for SSH connections', default='22', required=False), Input(name='enabled_metrics', type='list(string)', description='List of autoscaling group metrics to enable.', default='[]', required=False), Input(name='iam_instance_profile_name', type='string', description='If enable_iam_setup is false then this will be the name of the IAM instance profile to attach', default='', required=True), Input(name='server_rpc_port', type='number', description='The port used by servers to handle incoming requests from other agents.', default='8300', required=False), Input(name='cli_rpc_port', type='number', description='The port used by all agents to handle RPC from the CLI.', default='8400', required=False), Input(name='ami_id', type='string', description='The ID of the AMI to run in this cluster. Should be an AMI that had Consul installed and configured by the install-consul module.', default='', required=True), Input(name='vpc_id', type='string', description='The ID of the VPC in which to deploy the Consul cluster', default='', required=True), Input(name='cluster_tag_value', type='string', description='Add a tag with key var.clsuter_tag_key and this value to each Instance in the ASG. This can be used to automatically find other Consul nodes and form a cluster.', default='"auto-join"', required=False), Input(name='availability_zones', type='list(string)', description='The availability zones into which the EC2 Instances should be deployed. We recommend one availability zone per node in the cluster_size variable. At least one of var.subnet_ids or var.availability_zones must be non-empty.', default='', required=True), Input(name='associate_public_ip_address', type='bool', description='If set to true, associate a public IP address with each EC2 Instance in the cluster.', default='false', required=False), Input(name='root_volume_encrypted', type='bool', description='Encrypt the root volume at rest', default='false', required=False), Input(name='serf_wan_port', type='number', description='The port used by servers to gossip over the WAN to other servers.', default='8302', required=False), Input(name='security_group_tags', type='map(string)', description='Tags to be applied to the LC security group', default='{}', required=False), Input(name='spot_price', type='number', description='The maximum hourly price to pay for EC2 Spot Instances.', default='', required=True), Input(name='tenancy', type='string', description='The tenancy of the instance. Must be one of: null, default or dedicated. For EC2 Spot Instances only null or dedicated can be used.', default='', required=True), Input(name='enable_https_port', type='bool', description='If set to true, allow access to the Consul HTTPS port defined via the https_api_port variable.', default='false', required=False), Input(name='protect_from_scale_in', type='bool', description='(Optional) Allows setting instance protection. The autoscaling group will not select instances with this setting for termination during scale in events.', default='false', required=False), Input(name='cluster_name', type='string', description='The name of the Consul cluster (e.g. consul-stage). This variable is used to namespace all resources created by this module.', default='', required=True), Input(name='wait_for_capacity_timeout', type='string', description="A maximum duration that Terraform should wait for ASG instances to be healthy before timing out. Setting this to '0' causes Terraform to skip all Capacity Waiting behavior.", default='"10m"', required=False), Input(name='service_linked_role_arn', type='string', description='The ARN of the service-linked role that the ASG will use to call other AWS services', default='', required=True), Input(name='instance_type', type='string', description='The type of EC2 Instances to run for each node in the cluster (e.g. t2.micro).', default='', required=True), Input(name='allowed_inbound_cidr_blocks', type='list(string)', description='A list of CIDR-formatted IP address ranges from which the EC2 Instances will allow connections to Consul', default='', required=True), Input(name='allowed_inbound_security_group_count', type='number', description="The number of entries in var.allowed_inbound_security_group_ids. Ideally, this value could be computed dynamically, but we pass this variable to a Terraform resource's 'count' property and Terraform requires that 'count' be computed with literals or data sources only.", default='0', required=False), Input(name='health_check_grace_period', type='number', description='Time, in seconds, after instance comes into service before checking health.', default='300', required=False), Input(name='https_api_port', type='number', description='The port used by clients to talk to the HTTPS API. Only used if enable_https_port is set to true.', default='8501', required=False), Input(name='enable_iam_setup', type='bool', description='If true, create the IAM Role, IAM Instance Profile, and IAM Policies. If false, these will not be created, and you can pass in your own IAM Instance Profile via var.iam_instance_profile_name.', default='true', required=False), Input(name='cluster_tag_key', type='string', description='Add a tag with this key and the value var.cluster_tag_value to each Instance in the ASG. This can be used to automatically find other Consul nodes and form a cluster.', default='"consul-servers"', required=False), Input(name='ssh_key_name', type='string', description='The name of an EC2 Key Pair that can be used to SSH to the EC2 Instances in this cluster. Set to an empty string to not associate a Key Pair.', default='', required=True), Input(name='health_check_type', type='string', description='Controls how health checking is done. Must be one of EC2 or ELB.', default='"EC2"', required=False), Input(name='instance_profile_path', type='string', description='Path in which to create the IAM instance profile.', default='"/"', required=False), Input(name='serf_lan_port', type='number', description='The port used to handle gossip in the LAN. Required by all agents.', default='8301', required=False), Input(name='http_api_port', type='number', description='The port used by clients to talk to the HTTP API', default='8500', required=False), Input(name='iam_permissions_boundary', type='string', description='If set, restricts the created IAM role to the given permissions boundary', default='', required=True), Input(name='cluster_size', type='number', description='The number of nodes to have in the Consul cluster. We strongly recommended that you use either 3 or 5.', default='3', required=False), Input(name='allowed_ssh_cidr_blocks', type='list(string)', description='A list of CIDR-formatted IP address ranges from which the EC2 Instances will allow SSH connections', default='[]', required=False), Input(name='allowed_inbound_security_group_ids', type='list(string)', description='A list of security group IDs that will be allowed to connect to Consul', default='[]', required=False), Input(name='dns_port', type='number', description='The port used to resolve DNS queries.', default='8600', required=False), Input(name='tags', type='list(object({ key : string, value : string, propagate_at_launch : bool }))', description="List of extra tag blocks added to the autoscaling group configuration. Each element in the list is a map containing keys 'key', 'value', and 'propagate_at_launch' mapped to the respective values.", default='[]', required=False), Input(name='subnet_ids', type='list(string)', description='The subnet IDs into which the EC2 Instances should be deployed. We recommend one subnet ID per node in the cluster_size variable. At least one of var.subnet_ids or var.availability_zones must be non-empty.', default='', required=True), Input(name='termination_policies', type='string', description='A list of policies to decide how the instances in the auto scale group should be terminated. The allowed values are OldestInstance, NewestInstance, OldestLaunchConfiguration, ClosestToNextInstanceHour, Default.', default='"Default"', required=False), Input(name='lifecycle_hooks', type='map(any)', description='The lifecycle hooks to create that are triggered by the launch event. This is a map where the keys are the name of the hook and the values are an object with the keys and values defined in the lifecycle_hook block of the aws_autoscaling_group resource.  Default is no launch hooks', default='{}', required=False), Input(name='root_volume_ebs_optimized', type='bool', description='If true, the launched EC2 instance will be EBS-optimized.', default='false', required=False), Input(name='root_volume_size', type='number', description='The size, in GB, of the root EBS volume.', default='50', required=False), Input(name='root_volume_delete_on_termination', type='bool', description='Whether the volume should be destroyed on instance termination.', default='true', required=False)], outputs=[Output(name='launch_config_name', description='This is the name of the launch_configuration used to bootstrap the cluster instances'), Output(name='iam_role_arn', description='This is the arn of instance role if enable_iam_setup variable is set to true'), Output(name='iam_role_id', description='This is the id of instance role if enable_iam_setup variable is set to true'), Output(name='security_group_id', description='This is the id of security group that governs ingress and egress for the cluster instances'), Output(name='cluster_tag_key', description='This is the tag key used to allow the consul servers to autojoin'), Output(name='cluster_tag_value', description='This is the tag value used to allow the consul servers to autojoin'), Output(name='asg_name', description='This is the name for the autoscaling group generated by the module'), Output(name='cluster_size', description='This is the desired size of the consul cluster in the autoscaling group')], dependencies=[], provider_dependencies=[Provider(name='aws', namespace='', source='', version='')], resources=[Resource(name='launch_configuration', type='aws_launch_configuration'), Resource(name='lc_security_group', type='aws_security_group'), Resource(name='allow_ssh_inbound', type='aws_security_group_rule'), Resource(name='allow_ssh_inbound_from_security_group_ids', type='aws_security_group_rule'), Resource(name='allow_all_outbound', type='aws_security_group_rule'), Resource(name='instance_profile', type='aws_iam_instance_profile'), Resource(name='instance_role', type='aws_iam_role'), Resource(name='autoscaling_group', type='aws_autoscaling_group')]), ModuleInfo(path='modules/consul-security-group-rules', name='consul-security-group-rules', readme='# Consul Security Group Rules Module\n\nThis folder contains a [Terraform](https://www.terraform.io/) module that defines the security group rules used by a \n[Consul](https://www.consul.io/) cluster to control the traffic that is allowed to go in and out of the cluster. \n\nNormally, you\'d get these rules by default if you\'re using the [consul-cluster module](https://github.com/hashicorp/terraform-aws-consul/tree/master/modules/consul-cluster), but if \nyou\'re running Consul on top of a different cluster, then you can use this module to add the necessary security group \nrules to that cluster. For example, imagine you were using the [nomad-cluster \nmodule](https://github.com/hashicorp/terraform-aws-nomad/tree/master/modules/nomad-cluster) to run a cluster of \nservers that have both Nomad and Consul on each node:\n\n```hcl\nmodule "nomad_servers" {\n  source = "git::git@github.com:hashicorp/terraform-aws-nomad.git//modules/nomad-cluster?ref=v0.0.1"\n  \n  # This AMI has both Nomad and Consul installed\n  ami_id = "ami-1234abcd"\n}\n```\n\nThe `nomad-cluster` module will provide the security group rules for Nomad, but not for Consul. To ensure those servers\nhave the necessary ports open for using Consul, you can use this module as follows:\n\n```hcl\nmodule "security_group_rules" {\n  source = "git::git@github.com:hashicorp/terraform-aws-consul.git//modules/consul-security-group-rules?ref=v0.0.2"\n\n  security_group_id = "${module.nomad_servers.security_group_id}"\n  \n  # ... (other params omitted) ...\n}\n```\n\nNote the following parameters:\n\n* `source`: Use this parameter to specify the URL of this module. The double slash (`//`) is intentional \n  and required. Terraform uses it to specify subfolders within a Git repo (see [module \n  sources](https://www.terraform.io/docs/modules/sources.html)). The `ref` parameter specifies a specific Git tag in \n  this repo. That way, instead of using the latest version of this module from the `master` branch, which \n  will change every time you run Terraform, you\'re using a fixed version of the repo.\n\n* `security_group_id`: Use this parameter to specify the ID of the security group to which the rules in this module\n  should be added.\n  \nYou can find the other parameters in [variables.tf](variables.tf).\n\nCheck out the [consul-cluster example](https://github.com/hashicorp/terraform-aws-consul/tree/master/examples/root-example) for working sample code.\n', empty=False, inputs=[Input(name='security_group_id', type='string', description='The ID of the security group to which we should add the Consul security group rules', default='', required=True), Input(name='allowed_inbound_cidr_blocks', type='list(string)', description='A list of CIDR-formatted IP address ranges from which the EC2 Instances will allow connections to Consul', default='[]', required=False), Input(name='allowed_inbound_security_group_ids', type='list(string)', description='A list of security group IDs that will be allowed to connect to Consul', default='[]', required=False), Input(name='allowed_inbound_security_group_count', type='number', description="The number of entries in var.allowed_inbound_security_group_ids. Ideally, this value could be computed dynamically, but we pass this variable to a Terraform resource's 'count' property and Terraform requires that 'count' be computed with literals or data sources only.", default='0', required=False), Input(name='https_api_port', type='number', description='The port used by clients to talk to the HTTPS API. Only used if enable_https_port is set to true.', default='8501', required=False), Input(name='dns_port', type='number', description='The port used to resolve DNS queries.', default='8600', required=False), Input(name='server_rpc_port', type='number', description='The port used by servers to handle incoming requests from other agents.', default='8300', required=False), Input(name='cli_rpc_port', type='number', description='The port used by all agents to handle RPC from the CLI.', default='8400', required=False), Input(name='serf_lan_port', type='number', description='The port used to handle gossip in the LAN. Required by all agents.', default='8301', required=False), Input(name='serf_wan_port', type='number', description='The port used by servers to gossip over the WAN to other servers.', default='8302', required=False), Input(name='http_api_port', type='number', description='The port used by clients to talk to the HTTP API', default='8500', required=False), Input(name='enable_https_port', type='bool', description='If set to true, allow access to the Consul HTTPS port defined via the https_api_port variable.', default='false', required=False)], outputs=[], dependencies=[], provider_dependencies=[Provider(name='aws', namespace='', source='', version='')], resources=[Resource(name='allow_https_api_inbound_from_self', type='aws_security_group_rule'), Resource(name='allow_dns_udp_inbound_from_self', type='aws_security_group_rule'), Resource(name='allow_http_api_inbound', type='aws_security_group_rule'), Resource(name='allow_server_rpc_inbound_from_security_group_ids', type='aws_security_group_rule'), Resource(name='allow_serf_wan_udp_inbound_from_security_group_ids', type='aws_security_group_rule'), Resource(name='allow_http_api_inbound_from_self', type='aws_security_group_rule'), Resource(name='allow_serf_wan_tcp_inbound_from_security_group_ids', type='aws_security_group_rule'), Resource(name='allow_dns_udp_inbound_from_security_group_ids', type='aws_security_group_rule'), Resource(name='allow_server_rpc_inbound', type='aws_security_group_rule'), Resource(name='allow_cli_rpc_inbound', type='aws_security_group_rule'), Resource(name='allow_serf_wan_tcp_inbound', type='aws_security_group_rule'), Resource(name='allow_serf_wan_udp_inbound', type='aws_security_group_rule'), Resource(name='allow_server_rpc_inbound_from_self', type='aws_security_group_rule'), Resource(name='allow_serf_wan_udp_inbound_from_self', type='aws_security_group_rule'), Resource(name='allow_dns_tcp_inbound_from_self', type='aws_security_group_rule'), Resource(name='allow_dns_tcp_inbound', type='aws_security_group_rule'), Resource(name='allow_http_api_inbound_from_security_group_ids', type='aws_security_group_rule'), Resource(name='allow_https_api_inbound_from_security_group_ids', type='aws_security_group_rule'), Resource(name='allow_dns_tcp_inbound_from_security_group_ids', type='aws_security_group_rule'), Resource(name='allow_serf_wan_tcp_inbound_from_self', type='aws_security_group_rule'), Resource(name='allow_https_api_inbound', type='aws_security_group_rule'), Resource(name='allow_dns_udp_inbound', type='aws_security_group_rule'), Resource(name='allow_cli_rpc_inbound_from_security_group_ids', type='aws_security_group_rule'), Resource(name='allow_cli_rpc_inbound_from_self', type='aws_security_group_rule')]), ModuleInfo(path='modules/consul-client-security-group-rules', name='consul-client-security-group-rules', readme='# Consul Client Security Group Rules Module\n\nThis folder contains a [Terraform](https://www.terraform.io/) module that defines the security group rules used by a \n[Consul](https://www.consul.io/) client to control the traffic that is allowed to go in and out. \n\nNormally, you\'d get these rules by default if you\'re using the [consul-cluster module](https://github.com/hashicorp/terraform-aws-consul/tree/master/modules/consul-cluster), but if \nyou\'re running Consul on top of a different cluster, then you can use this module to add the necessary security group \nrules to that cluster. For example, imagine you were using the [vault-cluster \nmodule](https://github.com/hashicorp/terraform-aws-vault/tree/master/modules/vault-cluster) to run a cluster of \nservers that have both Vault and Consul agent on each node:\n\n```hcl\nmodule "vault_servers" {\n  source = "git::git@github.com:hashicorp/terraform-aws-vault.git//modules/vault-cluster?ref=v0.0.1"\n  \n  # This AMI has both Vault and Consul installed\n  ami_id = "ami-1234abcd"\n}\n```\n\nThe `vault-cluster` module will provide the security group rules for Vault, but not for the Consul agent. To ensure those servers\nhave the necessary ports open for using Consul, you can use this module as follows:\n\n```hcl\nmodule "security_group_rules" {\n  source = "git::git@github.com:hashicorp/terraform-aws-consul.git//modules/consul-client-security-group-rules?ref=v0.0.2"\n\n  security_group_id = "${module.vault_servers.security_group_id}"\n  \n  # ... (other params omitted) ...\n}\n```\n\nNote the following parameters:\n\n* `source`: Use this parameter to specify the URL of this module. The double slash (`//`) is intentional \n  and required. Terraform uses it to specify subfolders within a Git repo (see [module \n  sources](https://www.terraform.io/docs/modules/sources.html)). The `ref` parameter specifies a specific Git tag in \n  this repo. That way, instead of using the latest version of this module from the `master` branch, which \n  will change every time you run Terraform, you\'re using a fixed version of the repo.\n\n* `security_group_id`: Use this parameter to specify the ID of the security group to which the rules in this module\n  should be added.\n  \nYou can find the other parameters in [variables.tf](variables.tf).\n\nCheck out the [consul-cluster module](https://github.com/hashicorp/terraform-aws-consul/tree/master/modules/consul-cluster) for working sample code.\n', empty=False, inputs=[Input(name='allowed_inbound_security_group_ids', type='list(string)', description='A list of security group IDs that will be allowed to connect to Consul', default='[]', required=False), Input(name='allowed_inbound_security_group_count', type='string', description="The number of entries in var.allowed_inbound_security_group_ids. Ideally, this value could be computed dynamically, but we pass this variable to a Terraform resource's 'count' property and Terraform requires that 'count' be computed with literals or data sources only.", default='0', required=False), Input(name='serf_lan_port', type='string', description='The port used to handle gossip in the LAN. Required by all agents.', default='8301', required=False), Input(name='security_group_id', type='string', description='The ID of the security group to which we should add the Consul security group rules', default='', required=True), Input(name='allowed_inbound_cidr_blocks', type='list(string)', description='A list of CIDR-formatted IP address ranges from which the EC2 Instances will allow connections to Consul', default='[]', required=False)], outputs=[], dependencies=[], provider_dependencies=[Provider(name='aws', namespace='', source='', version='')], resources=[Resource(name='allow_serf_lan_tcp_inbound', type='aws_security_group_rule'), Resource(name='allow_serf_lan_udp_inbound', type='aws_security_group_rule'), Resource(name='allow_serf_lan_tcp_inbound_from_security_group_ids', type='aws_security_group_rule'), Resource(name='allow_serf_lan_udp_inbound_from_security_group_ids', type='aws_security_group_rule'), Resource(name='allow_serf_lan_tcp_inbound_from_self', type='aws_security_group_rule'), Resource(name='allow_serf_lan_udp_inbound_from_self', type='aws_security_group_rule')]), ModuleInfo(path='modules/consul-iam-policies', name='consul-iam-policies', readme='# Consul IAM Policies\n\nThis folder contains a [Terraform](https://www.terraform.io/) module that defines the IAM Policies used by a \n[Consul](https://www.consul.io/) cluster. \n\nNormally, you\'d get these policies by default if you\'re using the [consul-cluster submodule](https://github.com/hashicorp/terraform-aws-consul/tree/master/modules/consul-cluster), \nbut if you\'re running Consul on top of a different cluster (e.g. you\'re co-locating Consul with Nomad), then you can \nuse this module to add the necessary IAM policies to that that cluster. For example, imagine you were using the \n[nomad-cluster module](https://github.com/hashicorp/terraform-aws-nomad/tree/master/modules/nomad-cluster) to run a \ncluster of servers that have both Nomad and Consul on each node:\n\n```hcl\nmodule "nomad_servers" {\n  source = "git::git@github.com:hashicorp/terraform-aws-nomad.git//modules/nomad-cluster?ref=v0.0.1"\n  \n  # This AMI has both Nomad and Consul installed\n  ami_id = "ami-1234abcd"\n}\n```\n\nThe `nomad-cluster` module will provide the IAM policies for Nomad, but not for Consul. To ensure those servers\nhave the necessary IAM permissions to run Consul, you can use this module as follows:\n\n```hcl\nmodule "iam_policies" {\n  source = "git::git@github.com:hashicorp/terraform-aws-consul.git//modules/consul-iam-policies?ref=v0.0.2"\n\n  iam_role_id = "${module.nomad_servers.iam_role_id}"\n  \n  # ... (other params omitted) ...\n}\n```\n\nNote the following parameters:\n\n* `source`: Use this parameter to specify the URL of this module. The double slash (`//`) is intentional \n  and required. Terraform uses it to specify subfolders within a Git repo (see [module \n  sources](https://www.terraform.io/docs/modules/sources.html)). The `ref` parameter specifies a specific Git tag in \n  this repo. That way, instead of using the latest version of this module from the `master` branch, which \n  will change every time you run Terraform, you\'re using a fixed version of the repo.\n\n* `iam_role_id`: Use this parameter to specify the ID of the IAM Role to which the rules in this module\n  should be added.\n  \nYou can find the other parameters in [variables.tf](variables.tf).\n\nCheck out the [consul-cluster example](https://github.com/hashicorp/terraform-aws-consul/tree/master/examples/root-example) for working sample code.\n', empty=False, inputs=[Input(name='iam_role_id', type='string', description='The ID of the IAM Role to which these IAM policies should be attached', default='', required=True), Input(name='enabled', type='bool', description='Give the option to disable this module if required', default='true', required=False)], outputs=[], dependencies=[], provider_dependencies=[Provider(name='aws', namespace='', source='', version='')], resources=[Resource(name='auto_discover_cluster', type='aws_iam_role_policy')])], examples=[ModuleInfo(path='examples/example-with-encryption', name='example-with-encryption', readme="# Consul cluster with encryption example\n\nThis folder contains a set of Terraform manifest for deploying a Consul cluster in AWS, including a Packer manifest that creates an AMI with a set of insecured certs for TLS validation, as well as installing an updated version of the `run-consul` script that accepts parameters for enabling RPC and gossip encryption.\n\nThe resulting AMI id can then be passed as a parameter to `variables.tf`. The `enable_gossip_encryption` and `enable_rpc_encryption` variables are set to `true` by default in this example, but they don't have to be in your implementation. In this example they're passed as parameters to the `user_data` template to generate the flags passed to `run-consul` but you can use a different strategy.\n\nThe end result of this example should be a cluster of 3 Consul servers and 3 Consul clients, all running on individual EC2 instances. If the default variables are used, both gossip and RPC encryption will be enabled. You can validate this by trying to bring up another Consul node or cluster NOT running with encryption and attempt to join the existing cluster.\n\nRunning this example with encryption turned off and then attempt to upgrade it to use encryption is a good exercise to validate that a production cluster can be upgraded with minimal impact.\n\nTo understand more about how Consul handles encryption or how you can upgrade to use encryption without downtime, check out the [Consul encryption documentation](https://www.consul.io/docs/agent/encryption.html). **IMPORTANT:** The certs included in this repo are **NOT** meant to be used in production. You should generate your own certs if you're running this for anything other than experimenting or testing.\n\n## Quick start\n\nTo deploy a Consul cluster with encryption enabled:\n\n1. Create a new AMI using the Packer manifest and the certificates in the `packer` directory.\n1. Modify `main.tf` to add your provider credentials, VPC/subnet ids if you need to, etc.\n1. Modify `variables.tf` to customize the cluster. **NOTE:** the `gossip_encryption_key` variable must be a 16-byte key that can be generated offline with `consul keygen`. It's **NOT** a good idea to keep this key **in plain text** in source control. It should be encrypted beforehand (with something like KMS) and decrypted by Consul during boot.\n1. Run `terraform init`.\n1. Run `terraform apply`.\n1. `ssh` into one of the boxes and make sure all nodes correctly discover each other (by running `consul members` for example).\n1. You can also validate that encryption is turned on by looking at `/opt/consul/log/consul-stdout.log` and verifying you see `Encrypt: Gossip: true, TLS-Outgoing: true, TLS-Incoming: true`.", empty=False, inputs=[Input(name='vpc_id', type='string', description='The ID of the VPC in which the nodes will be deployed.  Uses default VPC if not supplied.', default='', required=True), Input(name='key_file_path', type='string', description='Path to the certificate key used to verify incoming connections.', default='"/opt/consul/tls/consul.key.pem"', required=False), Input(name='cluster_tag_key', type='string', description='The tag the EC2 Instances will look for to automatically discover each other and form a cluster.', default='"consul-servers"', required=False), Input(name='spot_price', type='string', description='The maximum hourly price to pay for EC2 Spot Instances.', default='', required=True), Input(name='gossip_encryption_key', type='string', description="16 byte cryptographic key to encrypt gossip traffic between nodes. Must set 'enable_gossip_encryption' to true for this to take effect. WARNING: Setting the encryption key here means it will be stored in plain text. We're doing this here to keep the example simple, but in production you should inject it more securely, e.g. retrieving it from KMS.", default='""', required=False), Input(name='ca_path', type='string', description='Path to the directory of CA files used to verify outgoing connections.', default='"/opt/consul/tls/ca"', required=False), Input(name='ssh_key_name', type='string', description='The name of an EC2 Key Pair that can be used to SSH to the EC2 Instances in this cluster. Set to an empty string to not associate a Key Pair.', default='', required=True), Input(name='enable_gossip_encryption', type='bool', description='Encrypt gossip traffic between nodes. Must also specify encryption key.', default='true', required=False), Input(name='enable_rpc_encryption', type='bool', description='Encrypt RPC traffic between nodes. Must also specify TLS certificates and keys.', default='true', required=False), Input(name='cert_file_path', type='string', description='Path to the certificate file used to verify incoming connections.', default='"/opt/consul/tls/consul.crt.pem"', required=False), Input(name='ami_id', type='string', description='The ID of the AMI to run in the cluster. This should be an AMI built from the Packer template under examples/example-with-encryption/packer/consul-with-certs.json. To keep this example simple, we run the same AMI on both server and client nodes, but in real-world usage, your client nodes would also run your apps. If the default value is used, Terraform will look up the latest AMI build automatically.', default='', required=True), Input(name='cluster_name', type='string', description='What to name the Consul cluster and all of its associated resources', default='"consul-example"', required=False), Input(name='num_servers', type='number', description='The number of Consul server nodes to deploy. We strongly recommend using 3 or 5.', default='3', required=False), Input(name='num_clients', type='number', description='The number of Consul client nodes to deploy. You typically run the Consul client alongside your apps, so set this value to however many Instances make sense for your app code.', default='3', required=False)], outputs=[Output(name='num_clients', description=''), Output(name='launch_config_name_clients', description=''), Output(name='asg_name_servers', description=''), Output(name='iam_role_arn_servers', description=''), Output(name='iam_role_arn_clients', description=''), Output(name='aws_region', description=''), Output(name='num_servers', description=''), Output(name='iam_role_id_servers', description=''), Output(name='asg_name_clients', description=''), Output(name='security_group_id_clients', description=''), Output(name='consul_servers_cluster_tag_value', description=''), Output(name='launch_config_name_servers', description=''), Output(name='security_group_id_servers', description=''), Output(name='iam_role_id_clients', description=''), Output(name='consul_servers_cluster_tag_key', description='')], dependencies=[], provider_dependencies=[Provider(name='aws', namespace='', source='', version='')], resources=[]), ModuleInfo(path='examples/example-with-custom-asg-role', name='example-with-custom-asg-role', readme="# Consul Cluster Example\n\nThis folder shows an example of Terraform code that uses the [consul-cluster module](https://github.com/hashicorp/terraform-aws-consul/tree/master/modules/consul-cluster) to deploy \na [Consul](https://www.consul.io/) cluster in [AWS](https://aws.amazon.com/). The cluster consists of two Auto Scaling\nGroups (ASGs): one with a small number of Consul server nodes, which are responsible for being part of the [consensus \nquorum](https://www.consul.io/docs/internals/consensus.html), and one with a larger number of client nodes, which \nwould typically run alongside your apps:\n\n![Consul architecture](https://github.com/hashicorp/terraform-aws-consul/blob/master/_docs/architecture.png?raw=true)\n\nThe Consul server nodes are launched using a custom autoscaling service-linked role for the autoscaling group instead of the default autoscaling service-linked role.  This enables a  custom role to be assigned which may be desired for using KMS encrypted AMIs.  [More Information](https://forums.aws.amazon.com/thread.jspa?threadID=277523)\n\nYou will need to create an [Amazon Machine Image (AMI)](http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/AMIs.html) \nthat has Consul installed, which you can do using the [consul-ami example](https://github.com/hashicorp/terraform-aws-consul/tree/master/examples/consul-ami)). Note that to keep \nthis example simple, both the server ASG and client ASG are running the exact same AMI. In real-world usage, you'd \nprobably have multiple client ASGs, and each of those ASGs would run a different AMI that has the Consul agent \ninstalled alongside your apps.\n\nFor more info on how the Consul cluster works, check out the [consul-cluster](https://github.com/hashicorp/terraform-aws-consul/tree/master/modules/consul-cluster) documentation.\n\n\n\n## Quick start\n\nTo deploy a Consul Cluster:\n\n1. `git clone` this repo to your computer.\n1. Optional: build a Consul AMI. See the [consul-ami example](https://github.com/hashicorp/terraform-aws-consul/tree/master/examples/consul-ami) documentation for instructions. Make sure to\n   note down the ID of the AMI.\n1. Install [Terraform](https://www.terraform.io/).\n1. Open `variables.tf`, set the environment variables specified at the top of the file, and fill in any other variables that\n   don't have a default. If you built a custom AMI, put the AMI ID into the `ami_id` variable. Otherwise, one of our\n   public example AMIs will be used by default. These AMIs are great for learning/experimenting, but are NOT\n   recommended for production use.\n1. Run `terraform init`.\n1. Run `terraform apply`.\n1. Run the [consul-examples-helper.sh script](https://github.com/hashicorp/terraform-aws-consul/tree/master/examples/consul-examples-helper/consul-examples-helper.sh) to \n   print out the IP addresses of the Consul servers and some example commands you can run to interact with the cluster:\n   `../consul-examples-helper/consul-examples-helper.sh`.\n\n", empty=False, inputs=[Input(name='vpc_id', type='string', description='The ID of the VPC in which the nodes will be deployed.  Uses default VPC if not supplied.', default='', required=True), Input(name='gossip_encryption_key', type='string', description="16 byte cryptographic key to encrypt gossip traffic between nodes. Must set 'enable_gossip_encryption' to true for this to take effect. WARNING: Setting the encryption key here means it will be stored in plain text. We're doing this here to keep the example simple, but in production you should inject it more securely, e.g. retrieving it from KMS.", default='', required=True), Input(name='consul_service_linked_role_suffix', type='string', description='Suffix for the aws_iam_service_linked_role created for the consul cluster auto scaling group to use', default='"test-consul-service-linked-role"', required=False), Input(name='ami_id', type='string', description='The ID of the AMI to run in the cluster. This should be an AMI built from the Packer template under examples/example-with-encryption/packer/consul-with-certs.json. To keep this example simple, we run the same AMI on both server and client nodes, but in real-world usage, your client nodes would also run your apps. If the default value is used, Terraform will look up the latest AMI build automatically.', default='', required=True), Input(name='ssh_key_name', type='string', description='The name of an EC2 Key Pair that can be used to SSH to the EC2 Instances in this cluster. Set to an empty string to not associate a Key Pair.', default='', required=True), Input(name='spot_price', type='string', description='The maximum hourly price to pay for EC2 Spot Instances.', default='', required=True), Input(name='cluster_name', type='string', description='What to name the Consul cluster and all of its associated resources', default='"consul-example"', required=False), Input(name='cluster_tag_key', type='string', description='The tag the EC2 Instances will look for to automatically discover each other and form a cluster.', default='"consul-servers"', required=False), Input(name='enable_gossip_encryption', type='bool', description='Encrypt gossip traffic between nodes. Must also specify encryption key.', default='true', required=False), Input(name='ca_path', type='string', description='Path to the directory of CA files used to verify outgoing connections.', default='"/opt/consul/tls/ca"', required=False), Input(name='cert_file_path', type='string', description='Path to the certificate file used to verify incoming connections.', default='"/opt/consul/tls/consul.crt.pem"', required=False), Input(name='num_clients', type='number', description='The number of Consul client nodes to deploy. You typically run the Consul client alongside your apps, so set this value to however many Instances make sense for your app code.', default='3', required=False), Input(name='enable_rpc_encryption', type='bool', description='Encrypt RPC traffic between nodes. Must also specify TLS certificates and keys.', default='true', required=False), Input(name='key_file_path', type='string', description='Path to the certificate key used to verify incoming connections.', default='"/opt/consul/tls/consul.key.pem"', required=False), Input(name='num_servers', type='number', description='The number of Consul server nodes to deploy. We strongly recommend using 3 or 5.', default='3', required=False)], outputs=[Output(name='launch_config_name_servers', description=''), Output(name='iam_role_arn_servers', description=''), Output(name='asg_name_clients', description=''), Output(name='launch_config_name_clients', description=''), Output(name='iam_role_id_clients', description=''), Output(name='consul_servers_cluster_tag_key', description=''), Output(name='iam_role_id_servers', description=''), Output(name='security_group_id_servers', description=''), Output(name='security_group_id_clients', description=''), Output(name='aws_region', description=''), Output(name='consul_servers_cluster_tag_value', description=''), Output(name='num_servers', description=''), Output(name='asg_name_servers', description=''), Output(name='num_clients', description=''), Output(name='iam_role_arn_clients', description='')], dependencies=[], provider_dependencies=[Provider(name='aws', namespace='', source='', version='')], resources=[Resource(name='consul_asg_role', type='aws_iam_service_linked_role')])], providers=['aws', 'azurerm', 'google'], versions=['0.0.1', '0.0.2', '0.0.3', '0.0.4', '0.0.5', '0.1.0', '0.1.1', '0.1.2', '0.2.0', '0.2.1', '0.2.2', '0.3.0', '0.3.1', '0.3.2', '0.3.3', '0.3.4', '0.3.5', '0.3.6', '0.3.7', '0.3.8', '0.3.9', '0.3.10', '0.4.0', '0.4.1', '0.4.2', '0.4.3', '0.4.4', '0.4.5', '0.5.0', '0.6.0', '0.6.1', '0.7.0', '0.7.1', '0.7.2', '0.7.3', '0.7.4', '0.7.5', '0.7.6', '0.7.7', '0.7.8', '0.7.9', '0.7.10', '0.7.11', '0.8.0', '0.8.1', '0.8.2', '0.8.3', '0.8.4', '0.8.5', '0.8.6', '0.9.0', '0.9.1', '0.9.2', '0.9.3', '0.10.0', '0.10.1', '0.11.0'], deprecation=None)
# ---
# name: test_list
  ModuleList(meta=Meta(limit=15, current_offset=0, next_offset=15, prev_offset=None, next_url='https://registry.terraform.io/v1/modules?offset=15'), modules=[ShortModule(id='GoogleCloudPlatform/lb-http/google/12.0.0', owner='', namespace='GoogleCloudPlatform', name='lb-http', version='12.0.0', provider='google', provider_logo_url='/images/providers/google-cloud.svg', description='Creates a global HTTP load balancer for Compute Engine by using forwarding rules', source='https://github.com/terraform-google-modules/terraform-google-lb-http', tag='v12.0.0', published_at='2024-09-17T16:58:50.45639Z', downloads=5283932, verified=True), ShortModule(id='GoogleCloudPlatform/managed-instance-group/google/1.1.15', owner='', namespace='GoogleCloudPlatform', name='managed-instance-group', version='1.1.15', provider='google', provider_logo_url='/images/providers/google-cloud.svg', description='Modular Google Compute Engine managed instance group for Terraform.', source='https://github.com/GoogleCloudPlatform/terraform-google-managed-instance-group', tag='1.1.15', published_at='2019-02-14T16:55:26.567562Z', downloads=158959, verified=True), ShortModule(id='GoogleCloudPlatform/lb-internal/google/7.0.0', owner='', namespace='GoogleCloudPlatform', name='lb-internal', version='7.0.0', provider='google', provider_logo_url='/images/providers/google-cloud.svg', description='Creates an internal load balancer for Compute Engine by using forwarding rules', source='https://github.com/terraform-google-modules/terraform-google-lb-internal', tag='v7.0.0', published_at='2024-10-07T17:43:57.6009Z', downloads=4394190, verified=True), ShortModule(id='GoogleCloudPlatform/nat-gateway/google/1.2.3', owner='', namespace='GoogleCloudPlatform', name='nat-gateway', version='1.2.3', provider='google', provider_logo_url='/images/providers/google-cloud.svg', description='Modular NAT Gateway on Google Compute Engine for Terraform.', source='https://github.com/GoogleCloudPlatform/terraform-google-nat-gateway', tag='v1.2.3', published_at='2020-02-12T16:37:09.082788Z', downloads=61574, verified=True), ShortModule(id='alibaba/ecs-instance/alicloud/2.12.0', owner='', namespace='alibaba', name='ecs-instance', version='2.12.0', provider='alicloud', provider_logo_url='/images/providers/alibaba.png?2', description='Terraform module which creates ECS instance(s) on Alibaba Cloud.', source='https://github.com/alibabacloud-automation/terraform-alicloud-ecs-instance', tag='v2.12.0', published_at='2024-08-08T11:42:47.317861Z', downloads=27950, verified=True), ShortModule(id='alibaba/slb/alicloud/2.1.0', owner='', namespace='alibaba', name='slb', version='2.1.0', provider='alicloud', provider_logo_url='/images/providers/alibaba.png?2', description='Terraform module which creates Load balancer and attach ECS instances in it on Alibaba Cloud.', source='https://github.com/alibabacloud-automation/terraform-alicloud-slb', tag='v2.1.0', published_at='2024-10-25T09:50:51.498721Z', downloads=4311, verified=True), ShortModule(id='alibaba/vpc/alicloud/1.11.0', owner='', namespace='alibaba', name='vpc', version='1.11.0', provider='alicloud', provider_logo_url='/images/providers/alibaba.png?2', description='Terraform module which creates VPC and Subnet resources on Alibaba Cloud.', source='https://github.com/alibabacloud-automation/terraform-alicloud-vpc', tag='v1.11.0', published_at='2024-09-10T09:39:55.550841Z', downloads=107341, verified=True), ShortModule(id='oracle/compute-instance/opc/1.0.1', owner='', namespace='oracle', name='compute-instance', version='1.0.1', provider='opc', provider_logo_url='/images/providers/oracle.svg', description='Terraform Module for creating Oracle Cloud Infrastructure OPC Compute instances', source='https://github.com/oracle/terraform-opc-compute-instance', tag='v1.0.1', published_at='2019-02-14T16:55:38.116329Z', downloads=973, verified=True), ShortModule(id='alibaba/security-group/alicloud/2.4.0', owner='', namespace='alibaba', name='security-group', version='2.4.0', provider='alicloud', provider_logo_url='/images/providers/alibaba.png?2', description='Terraform module which creates Security Group and sets rules for it on Alibaba Cloud.', source='https://github.com/alibabacloud-automation/terraform-alicloud-security-group', tag='v2.4.0', published_at='2021-08-29T13:02:46.663333Z', downloads=70734, verified=True), ShortModule(id='GoogleCloudPlatform/sql-db/google/23.0.0', owner='', namespace='GoogleCloudPlatform', name='sql-db', version='23.0.0', provider='google', provider_logo_url='/images/providers/google-cloud.svg', description='Creates a Cloud SQL database instance', source='https://github.com/terraform-google-modules/terraform-google-sql-db', tag='v23.0.0', published_at='2024-10-28T20:56:38.234394Z', downloads=11239813, verified=True), ShortModule(id='oracle/ip-networks/opc/1.0.0', owner='', namespace='oracle', name='ip-networks', version='1.0.0', provider='opc', provider_logo_url='/images/providers/oracle.svg', description='Terraform Module for creating Oracle Cloud Infrastructure OPC IP Neworks', source='https://github.com/oracle/terraform-opc-ip-networks', tag='v1.0.0', published_at='2019-02-14T16:56:16.669133Z', downloads=894, verified=True), ShortModule(id='GoogleCloudPlatform/lb/google/5.0.0', owner='', namespace='GoogleCloudPlatform', name='lb', version='5.0.0', provider='google', provider_logo_url='/images/providers/google-cloud.svg', description='Creates a regional TCP proxy load balancer for Compute Engine by using target pools and forwarding rules', source='https://github.com/terraform-google-modules/terraform-google-lb', tag='v5.0.0', published_at='2024-10-07T17:44:33.527429Z', downloads=41652, verified=True), ShortModule(id='terraform-alicloud-modules/slb-listener/alicloud/1.5.0', owner='', namespace='terraform-alicloud-modules', name='slb-listener', version='1.5.0', provider='alicloud', provider_logo_url='/images/providers/alibaba.png?2', description='A terraform module supports to create a specified load balancer listerner.', source='https://github.com/alibabacloud-automation/terraform-alicloud-slb-listener', tag='v1.5.0', published_at='2024-08-08T09:43:30.586294Z', downloads=2569, verified=True), ShortModule(id='terraform-alicloud-modules/kubernetes-wordpress/alicloud/1.0.1', owner='', namespace='terraform-alicloud-modules', name='kubernetes-wordpress', version='1.0.1', provider='alicloud', provider_logo_url='/images/providers/alibaba.png?2', description='Terraform module which deploys Wordpress and MySQL on Alibaba Cloud Kubernetes.', source='https://github.com/alibabacloud-automation/terraform-alicloud-kubernetes-wordpress', tag='v1.0.1', published_at='2018-09-19T09:45:39.358253Z', downloads=880, verified=True), ShortModule(id='terraform-alicloud-modules/disk/alicloud/1.5.0', owner='', namespace='terraform-alicloud-modules', name='disk', version='1.5.0', provider='alicloud', provider_logo_url='/images/providers/alibaba.png?2', description='Terraform module which creates ECS Disks and attach them to ECS instance on Alibaba Cloud', source='https://github.com/alibabacloud-automation/terraform-alicloud-disk', tag='v1.5.0', published_at='2021-12-10T07:42:49.674667Z', downloads=956, verified=True)])
# ---
# name: test_list_namespace
  ModuleList(meta=Meta(limit=15, current_offset=0, next_offset=15, prev_offset=None, next_url='https://registry.terraform.io/v1/modules/terraform-aws-modules?offset=15'), modules=[ShortModule(id='terraform-aws-modules/vpn-gateway/aws/3.7.2', owner='', namespace='terraform-aws-modules', name='vpn-gateway', version='3.7.2', provider='aws', provider_logo_url='/images/providers/aws.png', description='Terraform module to create AWS VPN gateway resources 🇺🇦', source='https://github.com/terraform-aws-modules/terraform-aws-vpn-gateway', tag='v3.7.2', published_at='2024-03-06T19:13:30.195817Z', downloads=1218303, verified=False), ShortModule(id='terraform-aws-modules/elb/aws/4.0.2', owner='', namespace='terraform-aws-modules', name='elb', version='4.0.2', provider='aws', provider_logo_url='/images/providers/aws.png', description='Terraform module to create AWS ELB resources 🇺🇦', source='https://github.com/terraform-aws-modules/terraform-aws-elb', tag='v4.0.2', published_at='2024-03-07T01:52:50.031907Z', downloads=1300590, verified=False), ShortModule(id='terraform-aws-modules/redshift/aws/6.0.0', owner='', namespace='terraform-aws-modules', name='redshift', version='6.0.0', provider='aws', provider_logo_url='/images/providers/aws.png', description='Terraform module to create AWS Redshift resources 🇺🇦', source='https://github.com/terraform-aws-modules/terraform-aws-redshift', tag='v6.0.0', published_at='2024-05-08T00:10:39.033442Z', downloads=1150761, verified=False), ShortModule(id='terraform-aws-modules/ecs/aws/5.11.4', owner='', namespace='terraform-aws-modules', name='ecs', version='5.11.4', provider='aws', provider_logo_url='/images/providers/aws.png', description='Terraform module to create AWS ECS resources 🇺🇦', source='https://github.com/terraform-aws-modules/terraform-aws-ecs', tag='v5.11.4', published_at='2024-08-07T23:52:14.385922Z', downloads=9016009, verified=False), ShortModule(id='terraform-aws-modules/autoscaling/aws/8.0.0', owner='', namespace='terraform-aws-modules', name='autoscaling', version='8.0.0', provider='aws', provider_logo_url='/images/providers/aws.png', description='Terraform module to create AWS Auto Scaling resources 🇺🇦', source='https://github.com/terraform-aws-modules/terraform-aws-autoscaling', tag='v8.0.0', published_at='2024-08-13T22:18:14.326172Z', downloads=10406918, verified=False), ShortModule(id='terraform-aws-modules/security-group/aws/5.2.0', owner='', namespace='terraform-aws-modules', name='security-group', version='5.2.0', provider='aws', provider_logo_url='/images/providers/aws.png', description='Terraform module to create AWS Security Group resources 🇺🇦', source='https://github.com/terraform-aws-modules/terraform-aws-security-group', tag='v5.2.0', published_at='2024-08-31T02:55:51.695369Z', downloads=62500151, verified=False), ShortModule(id='terraform-aws-modules/notify-slack/aws/6.5.0', owner='', namespace='terraform-aws-modules', name='notify-slack', version='6.5.0', provider='aws', provider_logo_url='/images/providers/aws.png', description='Terraform module to create AWS resources for sending notifications to Slack 🇺🇦', source='https://github.com/terraform-aws-modules/terraform-aws-notify-slack', tag='v6.5.0', published_at='2024-09-03T23:07:35.43115Z', downloads=4016445, verified=False), ShortModule(id='terraform-aws-modules/ec2-instance/aws/5.7.1', owner='', namespace='terraform-aws-modules', name='ec2-instance', version='5.7.1', provider='aws', provider_logo_url='/images/providers/aws.png', description='Terraform module to create AWS EC2 instance(s) resources 🇺🇦', source='https://github.com/terraform-aws-modules/terraform-aws-ec2-instance', tag='v5.7.1', published_at='2024-10-11T16:02:49.496252Z', downloads=18315835, verified=False), ShortModule(id='terraform-aws-modules/sns/aws/6.1.1', owner='', namespace='terraform-aws-modules', name='sns', version='6.1.1', provider='aws', provider_logo_url='/images/providers/aws.png', description='Terraform module to create AWS SNS resources 🇺🇦', source='https://github.com/terraform-aws-modules/terraform-aws-sns', tag='v6.1.1', published_at='2024-10-11T17:13:35.723307Z', downloads=5890474, verified=False), ShortModule(id='terraform-aws-modules/sqs/aws/4.2.1', owner='', namespace='terraform-aws-modules', name='sqs', version='4.2.1', provider='aws', provider_logo_url='/images/providers/aws.png', description='Terraform module to create AWS SQS resources 🇺🇦', source='https://github.com/terraform-aws-modules/terraform-aws-sqs', tag='v4.2.1', published_at='2024-10-11T17:14:13.008414Z', downloads=15955656, verified=False), ShortModule(id='terraform-aws-modules/rds-aurora/aws/9.10.0', owner='', namespace='terraform-aws-modules', name='rds-aurora', version='9.10.0', provider='aws', provider_logo_url='/images/providers/aws.png', description='Terraform module to create AWS RDS Aurora resources 🇺🇦', source='https://github.com/terraform-aws-modules/terraform-aws-rds-aurora', tag='v9.10.0', published_at='2024-10-15T16:15:20.644227Z', downloads=35138476, verified=False), ShortModule(id='terraform-aws-modules/rds/aws/6.10.0', owner='', namespace='terraform-aws-modules', name='rds', version='6.10.0', provider='aws', provider_logo_url='/images/providers/aws.png', description='Terraform module to create AWS RDS resources 🇺🇦', source='https://github.com/terraform-aws-modules/terraform-aws-rds', tag='v6.10.0', published_at='2024-10-16T14:39:49.423671Z', downloads=30532559, verified=False), ShortModule(id='terraform-aws-modules/alb/aws/9.12.0', owner='', namespace='terraform-aws-modules', name='alb', version='9.12.0', provider='aws', provider_logo_url='/images/providers/aws.png', description='Terraform module to create AWS Application/Network Load Balancer (ALB/NLB) resources 🇺🇦', source='https://github.com/terraform-aws-modules/terraform-aws-alb', tag='v9.12.0', published_at='2024-10-25T07:43:51.40697Z', downloads=25249241, verified=False), ShortModule(id='terraform-aws-modules/vpc/aws/5.15.0', owner='', namespace='terraform-aws-modules', name='vpc', version='5.15.0', provider='aws', provider_logo_url='/images/providers/aws.png', description='Terraform module to create AWS VPC resources 🇺🇦', source='https://github.com/terraform-aws-modules/terraform-aws-vpc', tag='v5.15.0', published_at='2024-11-03T05:44:47.179494Z', downloads=98225010, verified=False), ShortModule(id='terraform-aws-modules/iam/aws/5.48.0', owner='', namespace='terraform-aws-modules', name='iam', version='5.48.0', provider='aws', provider_logo_url='/images/providers/aws.png', description='Terraform module to create AWS IAM resources 🇺🇦', source='https://github.com/terraform-aws-modules/terraform-aws-iam', tag='v5.48.0', published_at='2024-11-11T14:57:59.971574Z', downloads=171240597, verified=False)])
# ---
# name: test_versions
  VersionList(meta=None, modules=[ModuleVersions(source='terraform-alicloud-modules/disk/alicloud', versions=[Version(version='1.0.0', root=ShortRoot(providers=[], dependencies=[], deprecation=None), submodules=[ShortSubmodule(path='modules/disk', providers=[Provider(name='alicloud', namespace='', source='', version='')], dependencies=[]), ShortSubmodule(path='modules/disk_attachment', providers=[Provider(name='alicloud', namespace='', source='', version='')], dependencies=[])], deprecation=None), Version(version='1.2.0', root=ShortRoot(providers=[], dependencies=[], deprecation=None), submodules=[ShortSubmodule(path='modules/disk', providers=[Provider(name='alicloud', namespace='', source='', version='')], dependencies=[]), ShortSubmodule(path='modules/disk_attachment', providers=[Provider(name='alicloud', namespace='', source='', version='')], dependencies=[])], deprecation=None), Version(version='1.3.0', root=ShortRoot(providers=[Provider(name='alicloud', namespace='', source='', version='>=1.56.0')], dependencies=[], deprecation=None), submodules=[ShortSubmodule(path='modules/disk', providers=[Provider(name='alicloud', namespace='', source='', version='')], dependencies=[]), ShortSubmodule(path='modules/disk_attachment', providers=[Provider(name='alicloud', namespace='', source='', version='')], dependencies=[])], deprecation=None), Version(version='1.4.0', root=ShortRoot(providers=[Provider(name='alicloud', namespace='', source='', version='>=1.56.0')], dependencies=[], deprecation=None), submodules=[ShortSubmodule(path='modules/disk', providers=[Provider(name='alicloud', namespace='', source='', version='')], dependencies=[]), ShortSubmodule(path='modules/disk_attachment', providers=[Provider(name='alicloud', namespace='', source='', version='')], dependencies=[])], deprecation=None), Version(version='1.5.0', root=ShortRoot(providers=[], dependencies=[], deprecation=None), submodules=[ShortSubmodule(path='modules/disk', providers=[Provider(name='alicloud', namespace='', source='', version='')], dependencies=[]), ShortSubmodule(path='modules/disk_attachment', providers=[Provider(name='alicloud', namespace='', source='', version='')], dependencies=[])], deprecation=None)])])
# ---
